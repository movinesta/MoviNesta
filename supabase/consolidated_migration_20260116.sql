-- Consolidated MoviNesta Migration - 2026-01-16
-- Generated by Antigravity
-- Encoding: UTF-8

-- -----------------------------------------------------------------------------
-- File: 20260116214500_consolidate_caches.sql
-- -----------------------------------------------------------------------------
-- Migration: Consolidate Cache Tables
-- Description: Merges OpenRouter, TMDB, and OMDB cache tables into generic 'external_api_cache' and 'media_metadata_cache' tables.

BEGIN;

--------------------------------------------------------------------------------
-- 1. Create new table: public.external_api_cache
--------------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS public.external_api_cache (
    key text NOT NULL,
    provider text NOT NULL,
    category text NOT NULL,
    fetched_at timestamp with time zone DEFAULT now() NOT NULL,
    expires_at timestamp with time zone,
    value jsonb DEFAULT '{}'::jsonb NOT NULL,
    CONSTRAINT external_api_cache_pkey PRIMARY KEY (key)
);

-- Add index/comment
COMMENT ON TABLE public.external_api_cache IS 'Consolidated cache for external API responses (e.g. OpenRouter).';
CREATE INDEX IF NOT EXISTS idx_external_api_cache_provider_category ON public.external_api_cache(provider, category);


--------------------------------------------------------------------------------
-- 2. Create new table: public.media_metadata_cache
--------------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS public.media_metadata_cache (
    provider text NOT NULL,     -- 'tmdb', 'omdb'
    external_id text NOT NULL,  -- 'tt1234567' or '12345'
    media_type text,            -- 'movie', 'series', 'person'
    fetched_at timestamp with time zone DEFAULT now() NOT NULL,
    data jsonb DEFAULT '{}'::jsonb NOT NULL,
    CONSTRAINT media_metadata_cache_pkey PRIMARY KEY (provider, external_id)
);

-- Add index/comment
COMMENT ON TABLE public.media_metadata_cache IS 'Consolidated cache for media metadata providers (TMDB, OMDB).';


--------------------------------------------------------------------------------
-- 3. Drop old tables (DATA WILL BE LOST per plan)
--------------------------------------------------------------------------------

-- OpenRouter tables
DROP TABLE IF EXISTS public.openrouter_credits_cache;
DROP TABLE IF EXISTS public.openrouter_endpoints_cache;
DROP TABLE IF EXISTS public.openrouter_key_cache;
DROP TABLE IF EXISTS public.openrouter_models_cache;
DROP TABLE IF EXISTS public.openrouter_usage_cache;
DROP TABLE IF EXISTS public.openrouter_parameters_cache;

-- Media tables
DROP TABLE IF EXISTS public.tmdb_cache;
DROP TABLE IF EXISTS public.omdb_cache;

COMMIT;



-- -----------------------------------------------------------------------------
-- File: 20260116215500_consolidate_user_prefs.sql
-- -----------------------------------------------------------------------------
-- Migration: Consolidate User Preferences
-- Description: Merges 5 separate preference tables into a single 'user_preferences' table with JSONB columns.

BEGIN;

--------------------------------------------------------------------------------
-- 1. Create new table: public.user_preferences
--------------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS public.user_preferences (
    user_id uuid NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
    
    -- Consolidated preference domains
    assistant jsonb DEFAULT '{}'::jsonb NOT NULL,      -- was assistant_prefs
    notifications jsonb DEFAULT '{}'::jsonb NOT NULL,  -- was notification_preferences
    recsys jsonb DEFAULT '{}'::jsonb NOT NULL,         -- was recsys_user_prefs
    swipe jsonb DEFAULT '{}'::jsonb NOT NULL,          -- was user_swipe_prefs
    settings jsonb DEFAULT '{}'::jsonb NOT NULL,       -- was user_settings
    
    updated_at timestamp with time zone DEFAULT now() NOT NULL,
    CONSTRAINT user_preferences_pkey PRIMARY KEY (user_id)
);

-- Add comment
COMMENT ON TABLE public.user_preferences IS 'Consolidated user preferences (Assistant, Notifications, RecSys, etc).';

-- Create RLS policies (simple owner access)
ALTER TABLE public.user_preferences ENABLE ROW LEVEL SECURITY;

DROP POLICY IF EXISTS "Users can view their own preferences" ON public.user_preferences;
CREATE POLICY "Users can view their own preferences" 
    ON public.user_preferences FOR SELECT 
    USING (auth.uid() = user_id);

DROP POLICY IF EXISTS "Users can update their own preferences" ON public.user_preferences;
CREATE POLICY "Users can update their own preferences" 
    ON public.user_preferences FOR UPDATE 
    USING (auth.uid() = user_id);

DROP POLICY IF EXISTS "Users can insert their own preferences" ON public.user_preferences;
CREATE POLICY "Users can insert their own preferences" 
    ON public.user_preferences FOR INSERT 
    WITH CHECK (auth.uid() = user_id);

--------------------------------------------------------------------------------
-- 2. Drop old tables (DATA WILL BE LOST per plan)
--------------------------------------------------------------------------------
DROP TABLE IF EXISTS public.assistant_prefs CASCADE;
DROP TABLE IF EXISTS public.notification_preferences CASCADE;
DROP TABLE IF EXISTS public.recsys_user_prefs CASCADE;
DROP TABLE IF EXISTS public.user_swipe_prefs CASCADE;
DROP TABLE IF EXISTS public.user_settings CASCADE;

COMMIT;



-- -----------------------------------------------------------------------------
-- File: 20260116223000_update_media_swipe_deck.sql
-- -----------------------------------------------------------------------------
CREATE OR REPLACE FUNCTION public.media_swipe_deck_v3_core(p_session_id uuid, p_limit integer, p_mode text, p_kind_filter text, p_seed text)
 RETURNS TABLE(media_item_id uuid, title text, overview text, kind text, release_date date, first_air_date date, omdb_runtime text, poster_path text, backdrop_path text, vote_average numeric, vote_count integer, popularity numeric, completeness numeric, source text, why text, friend_ids uuid[])
 LANGUAGE plpgsql
 SECURITY DEFINER
 SET search_path TO 'public', 'extensions', 'pg_temp'
AS $function$
#variable_conflict use_column
declare
  v_user_id uuid := auth.uid();

  v_muted_genres text[] := '{}'::text[];

  v_provider text;
  v_model text;
  v_dims int;
  v_task text;

  v_mode text := lower(coalesce(p_mode, 'combined'));

  -- accept: null, 'movie', or 'movie,series' (comma-separated)
  v_kind_filter text := nullif(lower(coalesce(p_kind_filter, '')), '');
  v_kind_filters text[];  -- derived from v_kind_filter

  v_limit int := greatest(1, least(120, coalesce(p_limit, 60)));

  -- Seed (computed after auth check)
  v_seed text;

  -- vectors
  v_session_vec vector;
  v_user_vec vector;
  v_has_vec boolean := false;

  -- session recency weight
  v_session_updated timestamptz;
  v_session_age_seconds double precision := 1e9;
  v_session_weight double precision := 0.0;

  -- diversity caps (soft constraints)
  v_genre_cap int := greatest(2, ceil(v_limit * 0.35)::int);
  v_collection_cap int := 2;

  -- why helpers
  v_recent_like_id uuid;
  v_recent_like_title text;

  -- cold-start detection (POSITIVE signals, not â€œany eventâ€)
  v_has_any_events boolean := false;
begin
  if v_user_id is null then
    return;
  end if;

  -- seed: allow caller; else stable daily seed (user_id + YYYY-MM-DD UTC)
  v_seed := coalesce(
    nullif(p_seed, ''),
    ('daily:' || v_user_id::text || ':' || to_char((now() at time zone 'utc')::date, 'YYYY-MM-DD'))
  );

  -- kind filters array (supports CSV)
  if v_kind_filter is not null then
    v_kind_filters := regexp_split_to_array(v_kind_filter, '\s*,\s*');
  else
    v_kind_filters := null;
  end if;

  -- Active embedding profile
  select active_provider, active_model, active_dimensions, active_task
    into v_provider, v_model, v_dims, v_task
  from public.embedding_settings
  where id = 1;


  -- Muted genres (user control / safety). Empty means no filtering.
  -- Refactored: read from user_preferences.recsys->mutedGenres
  select coalesce(
      (select array_agg(x) from jsonb_array_elements_text(up.recsys->'mutedGenres') x),
      '{}'::text[]
    )
    into v_muted_genres
  from public.user_preferences up
  where up.user_id = v_user_id;


  -- Any POSITIVE events?
  select exists(
    select 1
    from public.media_events e
    where e.user_id = v_user_id
      and e.created_at > now() - interval '120 days'
      and (
        e.event_type::text='like'
        or (e.event_type::text='watchlist' and e.in_watchlist=true)
        or (e.event_type::text='rating' and e.rating_0_10>=7)
        or (e.event_type::text='dwell' and e.dwell_ms>=6000)
        or (e.event_type::text='detail_open')
      )
    limit 1
  ) into v_has_any_events;

  -- session vector
  select sv.taste, sv.updated_at
    into v_session_vec, v_session_updated
  from public.media_session_vectors sv
  where sv.user_id=v_user_id
    and sv.session_id=p_session_id
    and sv.provider=v_provider and sv.model=v_model and sv.dimensions=v_dims and sv.task=v_task
  order by sv.updated_at desc
  limit 1;

  if v_session_updated is not null then
    v_session_age_seconds := extract(epoch from (now() - v_session_updated));
    -- half-life ~45 minutes
    v_session_weight := exp(-v_session_age_seconds / (45*60.0));
  end if;

  -- user vector
  select uv.taste
    into v_user_vec
  from public.media_user_vectors uv
  where uv.user_id=v_user_id
    and uv.provider=v_provider and uv.model=v_model and uv.dimensions=v_dims and uv.task=v_task
  order by uv.updated_at desc
  limit 1;

  v_has_vec := (v_user_vec is not null) or (v_session_vec is not null)
               or exists(
                 select 1 from public.media_user_centroids c
                 where c.user_id=v_user_id
                   and c.provider=v_provider and c.model=v_model and c.dimensions=v_dims and c.task=v_task
               );

  -- relaxed "recent positive" for explanations
  select e.media_item_id
    into v_recent_like_id
  from public.media_events e
  where e.user_id=v_user_id
    and e.created_at > now() - interval '30 days'
    and (
      e.event_type::text='like'
      or (e.event_type::text='watchlist' and e.in_watchlist=true)
      or (e.event_type::text='rating' and e.rating_0_10>=7)
      or (e.event_type::text='dwell' and e.dwell_ms>=6000)
      or (e.event_type::text='detail_open')
    )
  order by e.created_at desc
  limit 1;

  if v_recent_like_id is not null then
    select coalesce(mi.tmdb_title, mi.tmdb_name, mi.omdb_title)
      into v_recent_like_title
    from public.media_items mi
    where mi.id=v_recent_like_id;
  end if;

  ---------------------------------------------------------------------------
  -- temp tables
  ---------------------------------------------------------------------------
  create temporary table if not exists _cand (
    media_item_id uuid primary key,
    source text not null,
    score double precision not null,
    jit double precision not null,
    final_score double precision not null,
    primary_genre text,
    collection_id text,
    friend_ids uuid[],
    anchor_media_id uuid,
    anchor_title text
  ) on commit drop;
  truncate table _cand;

  create temporary table if not exists _take (
    media_item_id uuid primary key,
    source text not null,
    final_score double precision not null,
    primary_genre text,
    collection_id text,
    friend_ids uuid[],
    anchor_title text
  ) on commit drop;
  truncate table _take;

  create temporary table if not exists _picked (
    pos int primary key,
    media_item_id uuid not null,
    source text not null,
    final_score double precision not null,
    friend_ids uuid[],
    anchor_title text
  ) on commit drop;
  truncate table _picked;

  create temporary table if not exists _seen24h (media_item_id uuid primary key) on commit drop;
  truncate table _seen24h;

  insert into _seen24h(media_item_id)
  select x.media_item_id
  from (
    select mf.media_item_id
    from public.media_feedback mf
    where mf.user_id = v_user_id
      and mf.last_impression_at is not null
      and mf.last_impression_at > now() - interval '24 hours'

    union

    select e.media_item_id
    from public.media_events e
    where e.user_id = v_user_id
      and e.created_at > now() - interval '24 hours'
      and e.event_type in (
        'impression'::public.media_event_type,
        'dwell'::public.media_event_type,
        'skip'::public.media_event_type,
        'detail_open'::public.media_event_type,
        'detail_close'::public.media_event_type,
        'like'::public.media_event_type,
        'dislike'::public.media_event_type
      )
  ) x
  on conflict (media_item_id) do nothing;

  create temporary table if not exists _blocked (media_item_id uuid primary key) on commit drop;
  truncate table _blocked;

  -- block only strong negatives
  insert into _blocked(media_item_id)
  select x.media_item_id
  from (
    select mf.media_item_id
    from public.media_feedback mf
    where mf.user_id = v_user_id
      and (
        mf.last_action::text = 'dislike'
        or coalesce(mf.negative_ema,0) >= 0.95
      )

    union

    select e.media_item_id
    from public.media_events e
    where e.user_id = v_user_id
      and e.created_at > now() - interval '365 days'
      and (
        e.event_type = 'dislike'::public.media_event_type
        or (e.event_type::text='rating' and e.rating_0_10 is not null and e.rating_0_10 <= 3)
      )
  ) x
  on conflict (media_item_id) do nothing;

  create temporary table if not exists _served30m (media_item_id uuid primary key) on commit drop;
  truncate table _served30m;

  insert into _served30m(media_item_id)
  select ms.media_item_id
  from public.media_served ms
  where ms.user_id = v_user_id
    and ms.served_at > now() - interval '30 minutes'
  on conflict (media_item_id) do nothing;

  ---------------------------------------------------------------------------
  -- Candidate construction
  ---------------------------------------------------------------------------
  with
  params as (
    select v_mode as mode, v_kind_filters as kind_filters, v_seed as seed, v_has_vec as has_vec
  ),

  cents as (
    select taste
    from public.media_user_centroids c
    where c.user_id=v_user_id
      and c.provider=v_provider and c.model=v_model and c.dimensions=v_dims and c.task=v_task
    order by c.centroid asc
    limit 3
  ),

  -- POS anchors
  pos_anchors as (
    select
      e.media_item_id as anchor_id,
      me.embedding as anchor_emb,
      e.created_at
    from public.media_events e
    join public.media_embeddings me on me.media_item_id = e.media_item_id
    where e.user_id = v_user_id
      and e.created_at > now() - interval '120 days'
      and (
        e.event_type::text='like'
        or (e.event_type::text='watchlist' and e.in_watchlist=true)
        or (e.event_type::text='rating' and e.rating_0_10>=7)
        or (e.event_type::text='dwell' and e.dwell_ms>=6000)
        or (e.event_type::text='detail_open')
      )
      and me.provider=v_provider and me.model=v_model and me.dimensions=v_dims and me.task=v_task
      and not exists (select 1 from _blocked b where b.media_item_id = e.media_item_id)
    order by e.created_at desc
    limit 10
  ),

  anchor_neighbors_raw as (
    select
      n.media_item_id,
      n.anchor_id,
      n.sim
    from pos_anchors a
    cross join lateral (
      select
        a.anchor_id,
        me2.media_item_id,
        (1 - (me2.embedding <=> a.anchor_emb))::double precision as sim
      from public.media_embeddings me2
      where me2.provider=v_provider and me2.model=v_model and me2.dimensions=v_dims and me2.task=v_task
        and me2.media_item_id <> a.anchor_id
        and not exists (select 1 from _blocked b where b.media_item_id = me2.media_item_id)
      order by me2.embedding <=> a.anchor_emb
      limit (v_limit * 20)
    ) n
  ),

  anchor_neighbors as (
    select
      r.media_item_id,
      max(r.sim) as score,
      (array_agg(r.anchor_id order by r.sim desc))[1] as best_anchor_id
    from anchor_neighbors_raw r
    group by r.media_item_id
    order by score desc
    limit (v_limit * 60)
  ),

  anchor_neighbors_labeled as (
    select
      an.media_item_id,
      an.score,
      an.best_anchor_id as anchor_media_id,
      coalesce(mi.tmdb_title, mi.tmdb_name, mi.omdb_title) as anchor_title
    from anchor_neighbors an
    left join public.media_items mi on mi.id = an.best_anchor_id
  ),

  -- centroid/session/user fallback (only if anchors empty)
  session_neighbors as (
    select
      e.media_item_id,
      ((1 - (e.embedding <=> v_session_vec)) * v_session_weight)::double precision as score
    from public.media_embeddings e, params p
    where p.has_vec
      and v_session_vec is not null
      and e.provider=v_provider and e.model=v_model and e.dimensions=v_dims and e.task=v_task
      and not exists (select 1 from _blocked b where b.media_item_id=e.media_item_id)
    order by e.embedding <=> v_session_vec
    limit (v_limit * 30)
  ),

  user_neighbors as (
    select
      e.media_item_id,
      (1 - (e.embedding <=> v_user_vec))::double precision as score
    from public.media_embeddings e, params p
    where p.has_vec
      and v_user_vec is not null
      and e.provider=v_provider and e.model=v_model and e.dimensions=v_dims and e.task=v_task
      and not exists (select 1 from _blocked b where b.media_item_id=e.media_item_id)
    order by e.embedding <=> v_user_vec
    limit (v_limit * 30)
  ),

  centroid_neighbors_raw as (
    select
      n.media_item_id,
      n.sim
    from cents c
    cross join lateral (
      select
        me2.media_item_id,
        (1 - (me2.embedding <=> c.taste))::double precision as sim
      from public.media_embeddings me2, params p
      where p.has_vec
        and me2.provider=v_provider and me2.model=v_model and me2.dimensions=v_dims and me2.task=v_task
        and not exists (select 1 from _blocked b where b.media_item_id = me2.media_item_id)
      order by me2.embedding <=> c.taste
      limit (v_limit * 20)
    ) n
  ),

  centroid_neighbors as (
    select
      r.media_item_id,
      max(r.sim) as score
    from centroid_neighbors_raw r
    group by r.media_item_id
    order by score desc
    limit (v_limit * 40)
  ),

  for_you_centroid_candidates as (
    select * from session_neighbors
    union all select * from user_neighbors
    union all select * from centroid_neighbors
  ),

  for_you_centroid as (
    select
      c.media_item_id,
      max(c.score)::double precision as score
    from for_you_centroid_candidates c
    group by c.media_item_id
    order by score desc
    limit (v_limit * 30)
  ),

  -- cold-start for_you (learning): only if user has no POSITIVE events AND no vectors
  for_you_learning as (
    select
      mi.id as media_item_id,
      (
        coalesce(mi.tmdb_popularity,0)::double precision * 0.65
        + coalesce(mi.tmdb_vote_average,0)::double precision * 8.0
        + 0.15 * (
          (((hashtext(v_seed || mi.id::text))::bigint % 100000 + 100000) % 100000)::double precision / 100000.0
        )
      ) as score
    from public.media_items mi
    where (not v_has_any_events)
      and (not v_has_vec)
      and coalesce(mi.completeness,1.0) >= 0.25
      and (v_kind_filters is null or lower(mi.kind::text) = any (v_kind_filters))
      and mi.id not in (select media_item_id from _blocked)
    order by score desc
    limit (v_limit * 50)
  ),

  -- Trending vs Popular
  trending_recent as (
    select
      t.media_item_id,
      (t.score_72h * exp(-extract(epoch from (now() - t.computed_at)) / (18*3600.0)))::double precision as score
    from public.media_trending_scores t
    join public.media_items mi on mi.id=t.media_item_id
    where not exists (select 1 from _blocked b where b.media_item_id=t.media_item_id)
      and coalesce(mi.tmdb_release_date, mi.tmdb_first_air_date) >= ((now()::date - interval '6 months')::date)
    order by score desc
    limit (v_limit * 30)
  ),

  popular_catalog as (
    select
      t.media_item_id,
      (t.score_72h * exp(-extract(epoch from (now() - t.computed_at)) / (24*3600.0)) * 0.55)::double precision as score
    from public.media_trending_scores t
    join public.media_items mi on mi.id=t.media_item_id
    where not exists (select 1 from _blocked b where b.media_item_id=t.media_item_id)
      and coalesce(mi.tmdb_release_date, mi.tmdb_first_air_date) < ((now()::date - interval '6 months')::date)
    order by score desc
    limit (v_limit * 10)
  ),

  -- Friends
  friend_events as (
    select
      e.media_item_id,
      e.user_id as friend_id,
      e.created_at,
      case
        when e.event_type::text='like' then 2.0
        when e.event_type::text='watchlist' and e.in_watchlist=true then 1.6
        when e.event_type::text='rating' and e.rating_0_10>=7 then 1.2
        when e.event_type::text='dwell' and e.dwell_ms>=6000 then 0.8
        else 0.0
      end as w
    from public.follows f
    join public.media_events e on e.user_id=f.followed_id
    where f.follower_id=v_user_id
      and e.created_at > now() - interval '45 days'
      and e.event_type::text in ('like','watchlist','rating','dwell')
  ),

  friends as (
    select
      fe.media_item_id,
      sum(fe.w * exp(-extract(epoch from (now()-fe.created_at))/(7*24*3600.0)))::double precision as score,
      array_agg(distinct fe.friend_id) as friend_ids
    from friend_events fe
    where fe.w > 0
      and not exists (select 1 from _blocked b where b.media_item_id=fe.media_item_id)
    group by fe.media_item_id
    order by score desc
    limit (v_limit * 30)
  ),

  -- For-you pool
  for_you_pool as (
    select
      anl.media_item_id, anl.score, 'for_you'::text as source,
      null::uuid[] as friend_ids, anl.anchor_media_id, anl.anchor_title
    from anchor_neighbors_labeled anl

    union all

    select
      fyc.media_item_id, (fyc.score * 0.95) as score, 'for_you'::text as source,
      null::uuid[] as friend_ids, null::uuid as anchor_media_id, null::text as anchor_title
    from for_you_centroid fyc

    union all

    select
      fl.media_item_id, (fl.score * 0.8) as score, 'for_you'::text as source,
      null::uuid[] as friend_ids, null::uuid as anchor_media_id, null::text as anchor_title
    from for_you_learning fl
  )

  -- Insert candidates
  insert into _cand(media_item_id, source, score, jit, final_score, friend_ids, anchor_media_id, anchor_title)
  select
    x.media_item_id,
    x.source,
    x.score,
    0.0 as jit,
    x.score as final_score,
    x.friend_ids,
    x.anchor_media_id,
    x.anchor_title
  from (
    -- Mode-specific logic
    select * from for_you_pool where v_mode in ('for_you', 'combined')

    union all

    select media_item_id, score, 'trending'::text, null::uuid[], null::uuid, null::text
    from trending_recent
    where v_mode in ('trending', 'combined')

    union all

    select media_item_id, score, 'trending'::text, null::uuid[], null::uuid, null::text
    from popular_catalog
    where v_mode in ('trending', 'combined')

    union all

    select media_item_id, score, 'friends'::text, friend_ids, null::uuid, null::text
    from friends
    where v_mode in ('friends', 'combined')
  ) x
  where not exists (select 1 from _blocked b where b.media_item_id=x.media_item_id)
    and not exists (select 1 from _served30m s where s.media_item_id=x.media_item_id)
  on conflict (media_item_id) do update
    set score = greatest(_cand.score, excluded.score),
        source = case when excluded.score > _cand.score then excluded.source else _cand.source end,
        friend_ids = case when excluded.friend_ids is not null then excluded.friend_ids else _cand.friend_ids end;


  -- JIT random noise for freshness
  update _cand
  set jit = (
    (((hashtext(v_seed || media_item_id::text))::bigint % 100000 + 100000) % 100000)::double precision / 100000.0
  );

  -- Final score logic
  update _cand
  set final_score = case
      when source='for_you' then score + (jit * 0.05)
      when source='friends' then score + (jit * 0.05)
      else score + (jit * 0.15)
    end;

  -- Filter by kind
  if v_kind_filters is not null then
    delete from _cand c using public.media_items mi
    where c.media_item_id = mi.id
      and not (lower(mi.kind::text) = any(v_kind_filters));
  else
    -- if no filter, exclude 'episode' / 'other' to be safe
    delete from _cand c using public.media_items mi
    where c.media_item_id = mi.id
      and lower(mi.kind::text) in ('episode', 'other');
  end if;

  -- Filter by muted genres (best-effort soft filter)
  if array_length(v_muted_genres, 1) > 0 then
     -- This is expensive, so we only do it if mutated genres exist.
     delete from _cand c using public.media_items mi
     where c.media_item_id = mi.id
       and exists (
         select 1 from unnest(regexp_split_to_array(lower(coalesce(mi.omdb_genre,'')), '\s*,\s*')) t
         where t = any(v_muted_genres)
       );
  end if;


  -- Populate metadata
  update _cand
  set primary_genre = (regexp_split_to_array(mi.omdb_genre, ','))[1],
      collection_id = (mi.tmdb_belongs_to_collection ->> 'id')
  from public.media_items mi
  where _cand.media_item_id = mi.id;


  -- Take top N
  insert into _take
  select * from _cand order by final_score desc limit (v_limit * 3);


  -- Diversity selection (simple greedy MM with collection/genre caps)
  declare
    _r record;
    _taken_ids uuid[] := '{}';
    _genre_counts jsonb := '{}'::jsonb;
    _coll_counts jsonb := '{}'::jsonb;
    _g text;
    _c text;
    _ok boolean;
    _pass int := 0;
  begin
    for _r in (select * from _take order by final_score desc) loop
      if array_length(_taken_ids,1) >= v_limit then exit; end if;

      _ok := true;
      _g := lower(coalesce(_r.primary_genre, 'unknown'));
      _c := _r.collection_id;

      if (_genre_counts->>_g)::int >= v_genre_cap then _ok := false; end if;
      if _c is not null and (_coll_counts->>_c)::int >= v_collection_cap then _ok := false; end if;

      if _ok then
        insert into _picked(pos, media_item_id, source, final_score, friend_ids, anchor_title)
        values (array_length(_taken_ids,1)+1, _r.media_item_id, _r.source, _r.final_score, _r.friend_ids, _r.anchor_title);

        _taken_ids := _taken_ids || _r.media_item_id;
        _genre_counts := jsonb_set(_genre_counts, array[_g], ((coalesce(_genre_counts->>_g, '0')::int + 1)::text)::jsonb);
        if _c is not null then
          _coll_counts := jsonb_set(_coll_counts, array[_c], ((coalesce(_coll_counts->>_c, '0')::int + 1)::text)::jsonb);
        end if;
      end if;
    end loop;

    -- Fill if under limit
    if array_length(_taken_ids,1) < v_limit then
      for _r in (select * from _take where not (media_item_id = any(_taken_ids)) order by final_score desc) loop
        if array_length(_taken_ids,1) >= v_limit then exit; end if;
        insert into _picked(pos, media_item_id, source, final_score, friend_ids, anchor_title)
        values (array_length(_taken_ids,1)+1, _r.media_item_id, _r.source, _r.final_score, _r.friend_ids, _r.anchor_title);
        _taken_ids := _taken_ids || _r.media_item_id;
      end loop;
    end if;
  end;


  -- Return final result
  return query
  select
    mi.id as media_item_id,
    coalesce(mi.tmdb_title, mi.tmdb_name, mi.omdb_title) as title,
    coalesce(mi.tmdb_overview, mi.omdb_plot) as overview,
    mi.kind,
    mi.tmdb_release_date as release_date,
    mi.tmdb_first_air_date as first_air_date,
    mi.omdb_runtime,
    mi.tmdb_poster_path as poster_path,
    mi.tmdb_backdrop_path as backdrop_path,
    mi.tmdb_vote_average as vote_average,
    mi.tmdb_vote_count as vote_count,
    mi.tmdb_popularity as popularity,
    mi.completeness,
    p.source,
    case
      when p.source='friends' then 'Recommended by friends'
      when p.source='trending' then 'Trending on MoviNesta'
      when p.source='for_you' and p.anchor_title is not null then 'Because you liked ' || p.anchor_title
      else 'Recommended for you'
    end as why,
    p.friend_ids
  from _picked p
  join public.media_items mi on mi.id = p.media_item_id
  order by p.pos asc;

end;
$function$
;



-- -----------------------------------------------------------------------------
-- File: 20260116224500_consolidate_media_recsys.sql
-- -----------------------------------------------------------------------------
-- Phase 3: Consolidate Media & RecSys Tables
-- Merges rec_outcomes into media_events and drops media_served (redundant with rec_impressions)
-- Safe to run: No production data exists

BEGIN;

-----------------------------------------------------------------------
-- 1. Drop rec_outcomes table (schema nearly identical to media_events)
-----------------------------------------------------------------------
-- The rec_outcomes table duplicates media_events structure.
-- Going forward, all outcomes are logged via media_events with rec_request_id populated.

DROP TABLE IF EXISTS public.rec_outcomes CASCADE;

-----------------------------------------------------------------------
-- 2. Drop media_served table (superseded by rec_impressions)
-----------------------------------------------------------------------
-- media_served has only (user_id, media_item_id, served_at)
-- rec_impressions is more detailed and serves the same purpose

DROP TABLE IF EXISTS public.media_served CASCADE;

-----------------------------------------------------------------------
-- 3. Update media_swipe_deck_v3_core to use rec_impressions instead of media_served
-- (This is handled in a separate migration file for the RPC)
-----------------------------------------------------------------------

COMMIT;

-- Note: Code references to these tables must be refactored before applying this migration:
-- - Edge Functions: Scan for "rec_outcomes" and "media_served" usage
-- - SQL Functions: media_swipe_deck_v3_core uses media_served for 30-minute suppression



-- -----------------------------------------------------------------------------
-- File: 20260116225500_consolidate_rate_limits.sql
-- -----------------------------------------------------------------------------
-- Phase 4a: Consolidate Rate Limit Tables
-- Merges rate_limit_counters and rate_limit_state into a single rate_limits table

BEGIN;

-----------------------------------------------------------------------
-- 1. Create new consolidated rate_limits table
-----------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS public.rate_limits (
  key TEXT NOT NULL,
  action TEXT NOT NULL DEFAULT '',
  window_start TIMESTAMPTZ NOT NULL,
  count INTEGER NOT NULL DEFAULT 0,
  updated_at TIMESTAMPTZ DEFAULT now() NOT NULL,
  PRIMARY KEY (key, action)
);

ALTER TABLE public.rate_limits OWNER TO postgres;

-- Index for cleanup queries
CREATE INDEX IF NOT EXISTS idx_rate_limits_window_start ON public.rate_limits(window_start);

-- Grant permissions
GRANT ALL ON TABLE public.rate_limits TO anon;
GRANT ALL ON TABLE public.rate_limits TO authenticated;
GRANT ALL ON TABLE public.rate_limits TO service_role;

-----------------------------------------------------------------------
-- 2. Update check_rate_limit RPC to use new table
-----------------------------------------------------------------------
CREATE OR REPLACE FUNCTION public.check_rate_limit(p_key text, p_action text, p_max_per_minute integer)
 RETURNS TABLE(ok boolean, remaining integer, reset_at timestamp with time zone, retry_after_seconds integer)
 LANGUAGE plpgsql
 SECURITY DEFINER
 SET search_path TO 'public'
AS $$
declare
  v_now timestamptz := now();
  v_window_start timestamptz := date_trunc('minute', v_now);
  v_count int;
  v_reset timestamptz;
begin
  if p_key is null or p_key = '' or p_action is null or p_action = '' then
    return query select true, null::int, v_window_start + interval '1 minute', 0;
    return;
  end if;

  if p_max_per_minute is null or p_max_per_minute <= 0 then
    return query select true, null::int, v_window_start + interval '1 minute', 0;
    return;
  end if;

  -- Use new consolidated rate_limits table
  insert into public.rate_limits (key, action, window_start, count, updated_at)
  values (p_key, p_action, v_window_start, 1, now())
  on conflict (key, action) do update
    set window_start = case
      when public.rate_limits.window_start = v_window_start
        then public.rate_limits.window_start
      else v_window_start
    end,
    count = case
      when public.rate_limits.window_start = v_window_start
        then public.rate_limits.count + 1
      else 1
    end,
    updated_at = now()
  returning count, window_start into v_count, v_window_start;

  v_reset := v_window_start + interval '1 minute';

  return query select
    (v_count <= p_max_per_minute),
    greatest(p_max_per_minute - v_count, 0),
    v_reset,
    case
      when v_count <= p_max_per_minute then 0
      else greatest(ceil(extract(epoch from (v_reset - v_now)))::int, 1)
    end;
end;
$$;

-----------------------------------------------------------------------
-- 3. Drop old tables (no data to preserve)
-----------------------------------------------------------------------
DROP TABLE IF EXISTS public.rate_limit_counters CASCADE;
DROP TABLE IF EXISTS public.rate_limit_state CASCADE;

COMMIT;




-- -----------------------------------------------------------------------------
-- File: 20260116230000_profiles_public_to_view.sql
-- -----------------------------------------------------------------------------
-- Phase 5: Convert profiles_public table to view
-- Eliminates 3 sync triggers and ensures consistency

BEGIN;

-----------------------------------------------------------------------
-- 1. Drop triggers that sync profiles_public
-----------------------------------------------------------------------
DROP TRIGGER IF EXISTS trg_sync_profiles_public ON public.profiles;
DROP TRIGGER IF EXISTS trg_sync_profiles_public_delete ON public.profiles;
DROP TRIGGER IF EXISTS trg_sync_profiles_public_verification ON public.profile_verifications;

-----------------------------------------------------------------------
-- 2. Drop trigger functions
-----------------------------------------------------------------------
DROP FUNCTION IF EXISTS public.sync_profiles_public() CASCADE;
DROP FUNCTION IF EXISTS public.sync_profiles_public_delete() CASCADE;
DROP FUNCTION IF EXISTS public.sync_profiles_public_from_verification() CASCADE;

-----------------------------------------------------------------------
-- 3. Drop the table (or view if re-running)
-----------------------------------------------------------------------
DROP VIEW IF EXISTS public.profiles_public CASCADE;
DROP TABLE IF EXISTS public.profiles_public CASCADE;

-----------------------------------------------------------------------
-- 4. Create view from profiles + profile_verifications
-----------------------------------------------------------------------
CREATE VIEW public.profiles_public WITH (security_invoker = true) AS
SELECT
  p.id,
  p.username,
  p.display_name,
  p.avatar_url,
  NULL::text AS avatar_path,  -- deprecated, kept for compatibility
  p.bio,
  p.last_seen_at,
  p.created_at,
  p.updated_at,
  COALESCE(pv.status = 'approved', false) AS is_verified,
  pv.badge_type AS verified_type,
  pv.public_label AS verified_label,
  pv.verified_at,
  pv.verifier_org AS verified_by_org
FROM public.profiles p
LEFT JOIN public.profile_verifications pv 
  ON pv.user_id = p.id 
  AND pv.status = 'approved';

-----------------------------------------------------------------------
-- 5. Grant permissions (view inherits from profiles via security_invoker)
-----------------------------------------------------------------------
GRANT SELECT ON public.profiles_public TO anon;
GRANT SELECT ON public.profiles_public TO authenticated;
GRANT SELECT ON public.profiles_public TO service_role;

COMMIT;



-- -----------------------------------------------------------------------------
-- File: 20260116231000_partition_media_events.sql
-- -----------------------------------------------------------------------------
-- Scalability Phase 1: Partition media_events by event_day
-- This migration converts media_events to a partitioned table
-- IMPORTANT: Run during maintenance window - requires table recreation

BEGIN;

-- Scalability Phase 1: Partition media_events by event_day
-- This migration converts media_events to a partitioned table
-- IMPORTANT: Run during maintenance window - requires table recreation


DO $$
BEGIN
    -- Only proceed if media_events is NOT already partitioned
    IF NOT EXISTS (
        SELECT 1 
        FROM pg_partitioned_table 
        WHERE partrelid = 'public.media_events'::regclass
    ) THEN

        -----------------------------------------------------------------------
        -- 1. Create new partitioned table structure
        -----------------------------------------------------------------------
        CREATE TABLE IF NOT EXISTS public.media_events_partitioned (
            id uuid DEFAULT gen_random_uuid() NOT NULL,
            user_id uuid NOT NULL,
            session_id uuid NOT NULL,
            deck_id uuid,
            "position" integer,
            media_item_id uuid NOT NULL,
            event_type public.media_event_type NOT NULL,
            source text,
            dwell_ms integer,
            payload jsonb,
            created_at timestamp with time zone DEFAULT now() NOT NULL,
            client_event_id uuid,
            rating_0_10 numeric,
            in_watchlist boolean,
            event_day date DEFAULT ((now() AT TIME ZONE 'utc'::text))::date NOT NULL,
            dedupe_key text NOT NULL,
            rec_request_id uuid
        ) PARTITION BY RANGE (event_day);

        -----------------------------------------------------------------------
        -- 2. Create default partition
        -----------------------------------------------------------------------
        CREATE TABLE IF NOT EXISTS public.media_events_default 
            PARTITION OF public.media_events_partitioned DEFAULT;

        -----------------------------------------------------------------------
        -- 3. Create monthly partitions (next 6 months for efficiency)
        -----------------------------------------------------------------------
        CREATE TABLE IF NOT EXISTS public.media_events_2026_01 PARTITION OF public.media_events_partitioned FOR VALUES FROM ('2026-01-01') TO ('2026-02-01');
        CREATE TABLE IF NOT EXISTS public.media_events_2026_02 PARTITION OF public.media_events_partitioned FOR VALUES FROM ('2026-02-01') TO ('2026-03-01');
        CREATE TABLE IF NOT EXISTS public.media_events_2026_03 PARTITION OF public.media_events_partitioned FOR VALUES FROM ('2026-03-01') TO ('2026-04-01');
        CREATE TABLE IF NOT EXISTS public.media_events_2026_04 PARTITION OF public.media_events_partitioned FOR VALUES FROM ('2026-04-01') TO ('2026-05-01');
        CREATE TABLE IF NOT EXISTS public.media_events_2026_05 PARTITION OF public.media_events_partitioned FOR VALUES FROM ('2026-05-01') TO ('2026-06-01');
        CREATE TABLE IF NOT EXISTS public.media_events_2026_06 PARTITION OF public.media_events_partitioned FOR VALUES FROM ('2026-06-01') TO ('2026-07-01');

        -----------------------------------------------------------------------
        -- 4. Copy data from old table
        -----------------------------------------------------------------------
        INSERT INTO public.media_events_partitioned 
        SELECT * FROM public.media_events;

        -----------------------------------------------------------------------
        -- 5. Drop old table and rename new one
        -----------------------------------------------------------------------
        DROP TABLE public.media_events CASCADE;
        ALTER TABLE public.media_events_partitioned RENAME TO media_events;

        -----------------------------------------------------------------------
        -- 6. Recreate primary key and unique constraint
        -----------------------------------------------------------------------
        ALTER TABLE public.media_events 
            ADD CONSTRAINT media_events_pkey PRIMARY KEY (id, event_day);

        ALTER TABLE public.media_events 
            ADD CONSTRAINT media_events_user_dedupe_uq UNIQUE (user_id, dedupe_key, event_day);

        -----------------------------------------------------------------------
        -- 7. Recreate essential indexes (partitioned)
        -----------------------------------------------------------------------
        CREATE INDEX idx_media_events_user_day 
            ON public.media_events (user_id, event_day DESC);

        CREATE INDEX idx_media_events_user_item_time 
            ON public.media_events (user_id, media_item_id, created_at DESC);

        CREATE INDEX idx_media_events_event_type 
            ON public.media_events (event_type, created_at DESC);

        CREATE INDEX idx_media_events_media_item 
            ON public.media_events (media_item_id, event_day DESC);

        -----------------------------------------------------------------------
        -- 8. Grant permissions
        -----------------------------------------------------------------------
        GRANT ALL ON TABLE public.media_events TO anon;
        GRANT ALL ON TABLE public.media_events TO authenticated;
        GRANT ALL ON TABLE public.media_events TO service_role;

    END IF;
END $$;

-----------------------------------------------------------------------
-- 9. Create function to auto-create monthly partitions
-----------------------------------------------------------------------
CREATE OR REPLACE FUNCTION public.create_media_events_partition_if_needed()
RETURNS void
LANGUAGE plpgsql
AS $$
DECLARE
    partition_date date;
    partition_name text;
    start_date date;
    end_date date;
BEGIN
    -- Create partition for next month if it doesn't exist
    partition_date := date_trunc('month', now() + interval '1 month')::date;
    partition_name := 'media_events_' || to_char(partition_date, 'YYYY_MM');
    start_date := partition_date;
    end_date := partition_date + interval '1 month';
    
    IF NOT EXISTS (
        SELECT 1 FROM pg_tables 
        WHERE schemaname = 'public' AND tablename = partition_name
    ) THEN
        EXECUTE format(
            'CREATE TABLE public.%I PARTITION OF public.media_events FOR VALUES FROM (%L) TO (%L)',
            partition_name, start_date, end_date
        );
    END IF;
END;
$$;

COMMIT;



-- -----------------------------------------------------------------------------
-- File: 20260116231500_partition_rec_impressions.sql
-- -----------------------------------------------------------------------------
-- Scalability Phase 1: Partition rec_impressions by created_at
-- Similar to media_events, converts to monthly partitions

BEGIN;

DO $$
BEGIN
    -- Only proceed if rec_impressions is NOT already partitioned
    IF NOT EXISTS (
        SELECT 1 
        FROM pg_partitioned_table 
        WHERE partrelid = 'public.rec_impressions'::regclass
    ) THEN

        -----------------------------------------------------------------------
        -- 1. Create new partitioned table structure
        -----------------------------------------------------------------------
        CREATE TABLE IF NOT EXISTS public.rec_impressions_partitioned (
            id uuid DEFAULT gen_random_uuid() NOT NULL,
            rec_request_id uuid NOT NULL,
            user_id uuid NOT NULL,
            session_id uuid NOT NULL,
            deck_id uuid NOT NULL,
            media_item_id uuid NOT NULL,
            "position" integer NOT NULL,
            source text,
            dedupe_key text NOT NULL,
            request_context jsonb,
            created_at timestamp with time zone DEFAULT now() NOT NULL,
            created_day date DEFAULT ((now() AT TIME ZONE 'utc'::text))::date NOT NULL
        ) PARTITION BY RANGE (created_day);

        -----------------------------------------------------------------------
        -- 2. Create partitions
        -----------------------------------------------------------------------
        CREATE TABLE IF NOT EXISTS public.rec_impressions_default 
            PARTITION OF public.rec_impressions_partitioned DEFAULT;

        CREATE TABLE IF NOT EXISTS public.rec_impressions_2026_01 
            PARTITION OF public.rec_impressions_partitioned 
            FOR VALUES FROM ('2026-01-01') TO ('2026-02-01');

        CREATE TABLE IF NOT EXISTS public.rec_impressions_2026_02 
            PARTITION OF public.rec_impressions_partitioned 
            FOR VALUES FROM ('2026-02-01') TO ('2026-03-01');

        CREATE TABLE IF NOT EXISTS public.rec_impressions_2026_03 
            PARTITION OF public.rec_impressions_partitioned 
            FOR VALUES FROM ('2026-03-01') TO ('2026-04-01');

        -----------------------------------------------------------------------
        -- 3. Copy existing data
        -----------------------------------------------------------------------
        INSERT INTO public.rec_impressions_partitioned 
            (id, rec_request_id, user_id, session_id, deck_id, media_item_id, 
             "position", source, dedupe_key, request_context, created_at, created_day)
        SELECT 
            id, rec_request_id, user_id, session_id, deck_id, media_item_id,
            "position", source, dedupe_key, request_context, created_at,
            (created_at AT TIME ZONE 'utc')::date
        FROM public.rec_impressions;

        -----------------------------------------------------------------------
        -- 4. Swap tables
        -----------------------------------------------------------------------
        DROP TABLE public.rec_impressions CASCADE;
        ALTER TABLE public.rec_impressions_partitioned RENAME TO rec_impressions;

        -----------------------------------------------------------------------
        -- 5. Recreate constraints and indexes
        -----------------------------------------------------------------------
        ALTER TABLE public.rec_impressions 
            ADD CONSTRAINT rec_impressions_pkey PRIMARY KEY (id, created_day);

        CREATE INDEX idx_rec_impressions_user_item 
            ON public.rec_impressions (user_id, media_item_id);

        CREATE INDEX idx_rec_impressions_user_created 
            ON public.rec_impressions (user_id, created_at DESC);

        -----------------------------------------------------------------------
        -- 6. Grant permissions
        -----------------------------------------------------------------------
        GRANT ALL ON TABLE public.rec_impressions TO anon;
        GRANT ALL ON TABLE public.rec_impressions TO authenticated;
        GRANT ALL ON TABLE public.rec_impressions TO service_role;

    END IF;
END $$;

COMMIT;




-- -----------------------------------------------------------------------------
-- File: 20260116232000_retention_policies.sql
-- -----------------------------------------------------------------------------
-- Scalability Phase 1: Data Retention Policies
-- Automatic cleanup of old data to control storage growth

BEGIN;

-----------------------------------------------------------------------
-- 1. Function to delete old media_events partitions (>90 days)
-----------------------------------------------------------------------
CREATE OR REPLACE FUNCTION public.cleanup_old_media_events_partitions()
RETURNS integer
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
DECLARE
    partition_record record;
    cutoff_date date;
    deleted_count integer := 0;
BEGIN
    cutoff_date := (now() - interval '90 days')::date;
    
    FOR partition_record IN
        SELECT tablename 
        FROM pg_tables 
        WHERE schemaname = 'public' 
          AND tablename LIKE 'media_events_20%'
          AND tablename != 'media_events_default'
    LOOP
        -- Extract date from partition name (media_events_YYYY_MM)
        IF partition_record.tablename ~ '^media_events_[0-9]{4}_[0-9]{2}$' THEN
            IF to_date(replace(partition_record.tablename, 'media_events_', ''), 'YYYY_MM') < cutoff_date THEN
                EXECUTE format('DROP TABLE IF EXISTS public.%I', partition_record.tablename);
                deleted_count := deleted_count + 1;
            END IF;
        END IF;
    END LOOP;
    
    RETURN deleted_count;
END;
$$;

-----------------------------------------------------------------------
-- 2. Function to delete old rec_impressions partitions (>30 days)
-----------------------------------------------------------------------
CREATE OR REPLACE FUNCTION public.cleanup_old_rec_impressions_partitions()
RETURNS integer
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
DECLARE
    partition_record record;
    cutoff_date date;
    deleted_count integer := 0;
BEGIN
    cutoff_date := (now() - interval '30 days')::date;
    
    FOR partition_record IN
        SELECT tablename 
        FROM pg_tables 
        WHERE schemaname = 'public' 
          AND tablename LIKE 'rec_impressions_20%'
          AND tablename != 'rec_impressions_default'
    LOOP
        IF partition_record.tablename ~ '^rec_impressions_[0-9]{4}_[0-9]{2}$' THEN
            IF to_date(replace(partition_record.tablename, 'rec_impressions_', ''), 'YYYY_MM') < cutoff_date THEN
                EXECUTE format('DROP TABLE IF EXISTS public.%I', partition_record.tablename);
                deleted_count := deleted_count + 1;
            END IF;
        END IF;
    END LOOP;
    
    RETURN deleted_count;
END;
$$;

-----------------------------------------------------------------------
-- 3. Cleanup old notifications (read >30d, unread >90d)
-----------------------------------------------------------------------
CREATE OR REPLACE FUNCTION public.cleanup_old_notifications()
RETURNS integer
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
DECLARE
    deleted_count integer;
BEGIN
    WITH deleted AS (
        DELETE FROM public.notifications
        WHERE 
            (is_read AND created_at < now() - interval '30 days')
            OR (NOT is_read AND created_at < now() - interval '90 days')
        RETURNING id
    )
    SELECT count(*) INTO deleted_count FROM deleted;
    
    RETURN deleted_count;
END;
$$;

-----------------------------------------------------------------------
-- 4. Cleanup stale session vectors (>24h)
-----------------------------------------------------------------------
CREATE OR REPLACE FUNCTION public.cleanup_stale_session_vectors()
RETURNS integer
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
DECLARE
    deleted_count integer;
BEGIN
    WITH deleted AS (
        DELETE FROM public.media_session_vectors
        WHERE updated_at < now() - interval '24 hours'
        RETURNING user_id
    )
    SELECT count(*) INTO deleted_count FROM deleted;
    
    RETURN deleted_count;
END;
$$;

-----------------------------------------------------------------------
-- 5. Combined maintenance function (call from cron)
-----------------------------------------------------------------------
CREATE OR REPLACE FUNCTION public.run_data_retention_cleanup()
RETURNS jsonb
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
DECLARE
    result jsonb;
BEGIN
    result := jsonb_build_object(
        'notifications_deleted', public.cleanup_old_notifications(),
        'session_vectors_deleted', public.cleanup_stale_session_vectors(),
        'ran_at', now()
    );
    
    -- Also ensure next month's partitions exist
    PERFORM public.create_media_events_partition_if_needed();
    
    RETURN result;
END;
$$;

-----------------------------------------------------------------------
-- 6. Register in cron registry (if using pg_cron)
-----------------------------------------------------------------------
-- Run daily at 3 AM UTC:
-- SELECT cron.schedule('data-retention-cleanup', '0 3 * * *', 'SELECT public.run_data_retention_cleanup()');

COMMIT;



-- -----------------------------------------------------------------------------
-- File: 20260116232500_optimize_vectors.sql
-- -----------------------------------------------------------------------------
-- Scalability Phase 1: Vector Storage Optimization
-- Reduces storage and improves performance for embeddings

BEGIN;

-----------------------------------------------------------------------
-- 0. Drop views that depend on vector columns
-----------------------------------------------------------------------
-- These views must be dropped before altering technical column types
DROP VIEW IF EXISTS public.media_embeddings_active CASCADE;
DROP VIEW IF EXISTS public.media_user_vectors_active CASCADE;
DROP VIEW IF EXISTS public.media_session_vectors_active CASCADE;

-----------------------------------------------------------------------
-- 1. Convert media_embeddings to halfvec (float16)
-- Reduces storage by 50% with minimal quality loss
-----------------------------------------------------------------------

-- Create new table with halfvec
CREATE TABLE public.media_embeddings_optimized (
    media_item_id uuid NOT NULL,
    embedding extensions.halfvec(1024),  -- float16 instead of float32
    provider text DEFAULT 'jina'::text NOT NULL,
    model text DEFAULT 'jina-embeddings-v3'::text NOT NULL,
    dimensions integer DEFAULT 1024 NOT NULL,
    task text DEFAULT 'retrieval.passage'::text NOT NULL,
    updated_at timestamp with time zone DEFAULT now() NOT NULL,
    PRIMARY KEY (media_item_id, provider, model, task)
);

-- Copy data with cast to halfvec
INSERT INTO public.media_embeddings_optimized
SELECT 
    media_item_id,
    embedding::extensions.halfvec(1024),
    provider,
    model,
    dimensions,
    task,
    updated_at
FROM public.media_embeddings;

-- Swap tables
DROP TABLE public.media_embeddings CASCADE;
ALTER TABLE public.media_embeddings_optimized RENAME TO media_embeddings;

-- Recreate index for similarity search
CREATE INDEX idx_media_embeddings_hnsw 
    ON public.media_embeddings 
    USING hnsw (embedding extensions.halfvec_cosine_ops)
    WITH (m = 16, ef_construction = 64);

-- Grant permissions
GRANT ALL ON TABLE public.media_embeddings TO anon;
GRANT ALL ON TABLE public.media_embeddings TO authenticated;
GRANT ALL ON TABLE public.media_embeddings TO service_role;

-----------------------------------------------------------------------
-- 2. Optimize user vectors to halfvec
-----------------------------------------------------------------------
ALTER TABLE public.media_user_vectors 
    ALTER COLUMN taste TYPE extensions.halfvec(1024);

-----------------------------------------------------------------------
-- 3. Optimize session vectors to halfvec
-----------------------------------------------------------------------
ALTER TABLE public.media_session_vectors 
    ALTER COLUMN taste TYPE extensions.halfvec(1024);

-----------------------------------------------------------------------
-- 4. Optimize user centroids to halfvec
-----------------------------------------------------------------------
ALTER TABLE public.media_user_centroids 
    ALTER COLUMN taste TYPE extensions.halfvec;

-----------------------------------------------------------------------
-- 5. Recreate views (using correct joins to active_embedding_profile)
-----------------------------------------------------------------------

CREATE OR REPLACE VIEW public.media_embeddings_active WITH (security_invoker='true') AS
 SELECT me.media_item_id,
    me.embedding,
    me.model,
    me.task,
    me.updated_at,
    me.provider,
    me.dimensions
   FROM (public.media_embeddings me
     JOIN public.active_embedding_profile p ON (((me.provider = p.provider) AND (me.model = p.model) AND (me.dimensions = p.dimensions) AND (me.task = p.task))));

CREATE OR REPLACE VIEW public.media_user_vectors_active WITH (security_invoker='true') AS
 SELECT uv.user_id,
    uv.taste,
    uv.updated_at,
    uv.provider,
    uv.model,
    uv.dimensions,
    uv.task
   FROM (public.media_user_vectors uv
     JOIN public.active_embedding_profile p ON (((uv.provider = p.provider) AND (uv.model = p.model) AND (uv.dimensions = p.dimensions) AND (uv.task = p.task))));

CREATE OR REPLACE VIEW public.media_session_vectors_active WITH (security_invoker='true') AS
 SELECT sv.user_id,
    sv.session_id,
    sv.taste,
    sv.updated_at,
    sv.provider,
    sv.model,
    sv.dimensions,
    sv.task
   FROM (public.media_session_vectors sv
     JOIN public.active_embedding_profile p ON (((sv.provider = p.provider) AND (sv.model = p.model) AND (sv.dimensions = p.dimensions) AND (sv.task = p.task))));

COMMIT;




-- -----------------------------------------------------------------------------
-- File: 20260116233000_optimize_indexes.sql
-- -----------------------------------------------------------------------------
-- Scalability Phase 2: Index Optimization
-- Removes redundant indexes and adds missing ones for common queries

BEGIN;

-----------------------------------------------------------------------
-- 1. Remove redundant indexes on media_events
-- (Covered by partitioned table's implicit indexes)
-----------------------------------------------------------------------

-- These are now on partitions, not needed on parent
DROP INDEX IF EXISTS idx_media_events_dedupe;
DROP INDEX IF EXISTS media_events_client_event_id_idx;
DROP INDEX IF EXISTS media_events_created_at_idx;

-----------------------------------------------------------------------
-- 2. Add composite indexes for common query patterns
-----------------------------------------------------------------------

-- Fast lookup for swipe suppression (find recent dislikes)
CREATE INDEX IF NOT EXISTS idx_media_events_user_dislike_recent
    ON public.media_events (user_id, created_at DESC)
    WHERE event_type = 'dislike';

-- Fast lookup for watchlist state
CREATE INDEX IF NOT EXISTS idx_library_entries_user_status
    ON public.library_entries (user_id, status)
    INCLUDE (title_id);

-- Fast follower count
CREATE INDEX IF NOT EXISTS idx_follows_followed
    ON public.follows (followed_id);

-- Fast unread notification count
CREATE INDEX IF NOT EXISTS idx_notifications_user_unread
    ON public.notifications (user_id, created_at DESC)
    WHERE is_read = false;

-- Message search by conversation
CREATE INDEX IF NOT EXISTS idx_messages_conversation_time
    ON public.messages (conversation_id, created_at DESC);

-----------------------------------------------------------------------
-- 3. Add covering indexes for hot paths
-----------------------------------------------------------------------

-- Profile lookup (avoids table fetch for common fields)
CREATE INDEX IF NOT EXISTS idx_profiles_username_covering
    ON public.profiles (username)
    INCLUDE (id, display_name, avatar_url);

-- Media item basic info
CREATE INDEX IF NOT EXISTS idx_media_items_tmdb_covering
    ON public.media_items (tmdb_id, kind)
    INCLUDE (id, tmdb_title);

-----------------------------------------------------------------------
-- 4. Partial indexes for filtered queries
-----------------------------------------------------------------------

-- Only active library entries (not dropped)
CREATE INDEX IF NOT EXISTS idx_library_entries_active
    ON public.library_entries (user_id, updated_at DESC)
    WHERE status != 'dropped';

-- Only approved verifications
CREATE INDEX IF NOT EXISTS idx_profile_verifications_approved
    ON public.profile_verifications (user_id)
    WHERE status = 'approved';

-----------------------------------------------------------------------
-- 5. Analyze tables to update statistics
-----------------------------------------------------------------------
ANALYZE public.media_events;
ANALYZE public.library_entries;
ANALYZE public.profiles;
ANALYZE public.follows;
ANALYZE public.notifications;
ANALYZE public.messages;

COMMIT;



-- -----------------------------------------------------------------------------
-- File: 20260116233500_materialized_views.sql
-- -----------------------------------------------------------------------------
-- Scalability Phase 2: Materialized Views for Expensive Aggregates
-- Pre-computes expensive counts and aggregations

BEGIN;

-----------------------------------------------------------------------
-- 1. Materialized view for user stats (replaces live counting)
-----------------------------------------------------------------------
CREATE MATERIALIZED VIEW IF NOT EXISTS public.user_stats_mv AS
SELECT 
    p.id AS user_id,
    (SELECT COUNT(*) FROM public.follows WHERE followed_id = p.id) AS followers_count,
    (SELECT COUNT(*) FROM public.follows WHERE follower_id = p.id) AS following_count,
    (SELECT COUNT(*) FROM public.ratings WHERE user_id = p.id) AS ratings_count,
    (SELECT COUNT(*) FROM public.reviews WHERE user_id = p.id) AS reviews_count,
    (SELECT COUNT(*) FROM public.library_entries WHERE user_id = p.id AND status = 'want_to_watch') AS watchlist_count,
    (SELECT COUNT(*) FROM public.comments WHERE user_id = p.id) AS comments_count,
    (SELECT COUNT(*) FROM public.lists WHERE user_id = p.id AND is_public = true) AS lists_count,
    now() AS refreshed_at
FROM public.profiles p;

CREATE UNIQUE INDEX ON public.user_stats_mv (user_id);

-- Refresh function
CREATE OR REPLACE FUNCTION public.refresh_user_stats_mv()
RETURNS void
LANGUAGE sql
SECURITY DEFINER
AS $$
    REFRESH MATERIALIZED VIEW CONCURRENTLY public.user_stats_mv;
$$;

-----------------------------------------------------------------------
-- 2. Materialized view for trending media (refreshed hourly)
-----------------------------------------------------------------------
CREATE MATERIALIZED VIEW IF NOT EXISTS public.media_trending_mv AS
SELECT 
    media_item_id,
    SUM(CASE WHEN event_type = 'like' THEN 1 ELSE 0 END) AS likes_72h,
    SUM(CASE WHEN event_type = 'dislike' THEN 1 ELSE 0 END) AS dislikes_72h,
    SUM(CASE WHEN event_type = 'impression' THEN 1 ELSE 0 END) AS impressions_72h,
    COUNT(DISTINCT user_id) AS unique_users_72h,
    -- Wilson score for ranking
    (SUM(CASE WHEN event_type = 'like' THEN 1.0 ELSE 0.0 END) + 1.9208) / 
    (SUM(CASE WHEN event_type IN ('like', 'dislike') THEN 1.0 ELSE 0.0 END) + 3.8416) -
    1.96 * SQRT(
        (SUM(CASE WHEN event_type = 'like' THEN 1.0 ELSE 0.0 END) * 
         SUM(CASE WHEN event_type = 'dislike' THEN 1.0 ELSE 0.0 END)) / 
        NULLIF(SUM(CASE WHEN event_type IN ('like', 'dislike') THEN 1.0 ELSE 0.0 END), 0) + 0.9604
    ) / (SUM(CASE WHEN event_type IN ('like', 'dislike') THEN 1.0 ELSE 0.0 END) + 3.8416) AS wilson_score,
    now() AS refreshed_at
FROM public.media_events
WHERE created_at > now() - interval '72 hours'
  AND event_type IN ('like', 'dislike', 'impression')
GROUP BY media_item_id
HAVING SUM(CASE WHEN event_type = 'impression' THEN 1 ELSE 0 END) >= 10;

CREATE UNIQUE INDEX ON public.media_trending_mv (media_item_id);
CREATE INDEX ON public.media_trending_mv (wilson_score DESC);

-- Refresh function
CREATE OR REPLACE FUNCTION public.refresh_media_trending_mv()
RETURNS void
LANGUAGE sql
SECURITY DEFINER
AS $$
    REFRESH MATERIALIZED VIEW CONCURRENTLY public.media_trending_mv;
$$;

-----------------------------------------------------------------------
-- 3. Grant permissions
-----------------------------------------------------------------------
GRANT SELECT ON public.user_stats_mv TO anon;
GRANT SELECT ON public.user_stats_mv TO authenticated;
GRANT SELECT ON public.user_stats_mv TO service_role;

GRANT SELECT ON public.media_trending_mv TO anon;
GRANT SELECT ON public.media_trending_mv TO authenticated;
GRANT SELECT ON public.media_trending_mv TO service_role;

COMMIT;



-- -----------------------------------------------------------------------------
-- File: 20260116234000_scheduled_maintenance.sql
-- -----------------------------------------------------------------------------
-- Scalability Phase 2: Scheduled Maintenance Jobs
-- Configures pg_cron for automated maintenance

BEGIN;

-----------------------------------------------------------------------
-- 1. Register maintenance jobs (requires pg_cron extension)
-----------------------------------------------------------------------

-- Enable pg_cron if not already enabled
-- Note: This requires Supabase Pro plan or higher
-- CREATE EXTENSION IF NOT EXISTS pg_cron;

-----------------------------------------------------------------------
-- 2. Master scheduler function
-----------------------------------------------------------------------
CREATE OR REPLACE FUNCTION public.run_scheduled_maintenance()
RETURNS jsonb
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
DECLARE
    result jsonb := '{}';
    retention_result jsonb;
BEGIN
    -- 1. Data retention cleanup
    retention_result := public.run_data_retention_cleanup();
    result := result || jsonb_build_object('retention', retention_result);
    
    -- 2. Refresh materialized views
    PERFORM public.refresh_user_stats_mv();
    result := result || jsonb_build_object('user_stats_refreshed', true);
    
    PERFORM public.refresh_media_trending_mv();
    result := result || jsonb_build_object('media_trending_refreshed', true);
    
    -- 3. Create next month's partitions
    PERFORM public.create_media_events_partition_if_needed();
    result := result || jsonb_build_object('partitions_checked', true);
    
    -- 4. Vacuum analyze high-churn tables
    -- Note: VACUUM ANALYZE runs automatically but we force it for key tables
    ANALYZE public.media_events;
    ANALYZE public.rec_impressions;
    ANALYZE public.notifications;
    result := result || jsonb_build_object('analyze_ran', true);
    
    result := result || jsonb_build_object('completed_at', now());
    
    -- Log the run
    INSERT INTO public.job_run_log (job_name, status, details, ran_at)
    VALUES ('scheduled_maintenance', 'success', result, now())
    ON CONFLICT DO NOTHING;
    
    RETURN result;
EXCEPTION WHEN OTHERS THEN
    -- Log failure
    INSERT INTO public.job_run_log (job_name, status, details, ran_at)
    VALUES ('scheduled_maintenance', 'error', jsonb_build_object('error', SQLERRM), now())
    ON CONFLICT DO NOTHING;
    RAISE;
END;
$$;

-----------------------------------------------------------------------
-- 3. Individual refresh functions for hourly jobs
-----------------------------------------------------------------------
CREATE OR REPLACE FUNCTION public.refresh_trending_hourly()
RETURNS void
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
BEGIN
    PERFORM public.refresh_media_trending_mv();
END;
$$;

-----------------------------------------------------------------------
-- 4. Cron schedule commands (run these manually or via Supabase dashboard)
-----------------------------------------------------------------------

-- Daily maintenance at 3 AM UTC
-- SELECT cron.schedule('daily-maintenance', '0 3 * * *', 'SELECT public.run_scheduled_maintenance()');

-- Hourly trending refresh
-- SELECT cron.schedule('hourly-trending', '0 * * * *', 'SELECT public.refresh_trending_hourly()');

-- Weekly full vacuum (Sunday 4 AM UTC) - requires superuser
-- SELECT cron.schedule('weekly-vacuum', '0 4 * * 0', 'VACUUM ANALYZE');

COMMIT;



-- -----------------------------------------------------------------------------
-- File: 20260116235000_consolidate_assistant.sql
-- -----------------------------------------------------------------------------
-- Phase 6: Consolidate Assistant Tables
-- Merges assistant_goal_state into assistant_goals
-- Folds assistant_failures into ops_alerts

BEGIN;

-----------------------------------------------------------------------
-- 1. Extend assistant_goals with state columns
-----------------------------------------------------------------------
ALTER TABLE public.assistant_goals 
    ADD COLUMN IF NOT EXISTS target_count integer DEFAULT 0 NOT NULL,
    ADD COLUMN IF NOT EXISTS progress_count integer DEFAULT 0 NOT NULL,
    ADD COLUMN IF NOT EXISTS last_event_at timestamp with time zone;

DO $$
BEGIN
    -----------------------------------------------------------------------
    -- 2. Migrate data from assistant_goal_state (if table exists)
    -----------------------------------------------------------------------
    IF EXISTS (SELECT 1 FROM pg_tables WHERE schemaname = 'public' AND tablename = 'assistant_goal_state') THEN
        UPDATE public.assistant_goals ag
        SET 
            target_count = ags.target_count,
            progress_count = ags.progress_count,
            last_event_at = ags.last_event_at,
            updated_at = ags.updated_at
        FROM public.assistant_goal_state ags
        WHERE ag.id = ags.goal_id;
        
        DROP TABLE public.assistant_goal_state CASCADE;
    END IF;
END $$;

DO $$
BEGIN
    -----------------------------------------------------------------------
    -- 4. Migrate assistant_failures to ops_alerts (if table exists)
    -----------------------------------------------------------------------
    IF EXISTS (SELECT 1 FROM pg_tables WHERE schemaname = 'public' AND tablename = 'assistant_failures') THEN
        INSERT INTO public.ops_alerts (kind, severity, title, detail, source, dedupe_key, meta, created_at, updated_at)
        SELECT 
            'assistant_failure'::text as kind,
            'warn'::text as severity,
            'Assistant Failure: ' || code as title,
            message as detail,
            'assistant_telemetry'::text as source,
            'fail_' || id as dedupe_key,
            jsonb_build_object(
                'code', code,
                'user_id', user_id,
                'conversation_id', conversation_id,
                'original_details', details
            ) as meta,
            now() as created_at,
            now() as updated_at
        FROM public.assistant_failures;
        
        DROP TABLE public.assistant_failures CASCADE;
    END IF;
END $$;

COMMIT;



-- -----------------------------------------------------------------------------
-- File: 20260116235500_fix_swipe_deck_alignment.sql
-- -----------------------------------------------------------------------------
-- Phase 7: Deep Alignment Fixes
-- This migration fixes several RPCs and Views that were still referencing dropped tables or old structures.

BEGIN;

-----------------------------------------------------------------------
-- 1. Fix media_swipe_deck_v3_core (Use rec_impressions instead of media_served)
-----------------------------------------------------------------------
CREATE OR REPLACE FUNCTION public.media_swipe_deck_v3_core(p_session_id uuid, p_limit integer, p_mode text, p_kind_filter text, p_seed text)
 RETURNS TABLE(media_item_id uuid, title text, overview text, kind text, release_date date, first_air_date date, omdb_runtime text, poster_path text, backdrop_path text, vote_average numeric, vote_count integer, popularity numeric, completeness numeric, source text, why text, friend_ids uuid[])
 LANGUAGE plpgsql
 SECURITY DEFINER
 SET search_path TO 'public', 'extensions', 'pg_temp'
AS $function$
#variable_conflict use_column
declare
  v_user_id uuid := auth.uid();
  v_muted_genres text[] := '{}'::text[];
  v_provider text;
  v_model text;
  v_dims int;
  v_task text;
  v_mode text := lower(coalesce(p_mode, 'combined'));
  v_kind_filter text := nullif(lower(coalesce(p_kind_filter, '')), '');
  v_kind_filters text[];
  v_limit int := greatest(1, least(120, coalesce(p_limit, 60)));
  v_seed text;
  v_session_vec vector;
  v_user_vec vector;
  v_has_vec boolean := false;
  v_session_updated timestamptz;
  v_session_age_seconds double precision := 1e9;
  v_session_weight double precision := 0.0;
  v_genre_cap int := greatest(2, ceil(v_limit * 0.35)::int);
  v_collection_cap int := 2;
  v_recent_like_id uuid;
  v_recent_like_title text;
  v_has_any_events boolean := false;
begin
  if v_user_id is null then return; end if;

  v_seed := coalesce(nullif(p_seed, ''), ('daily:' || v_user_id::text || ':' || to_char((now() at time zone 'utc')::date, 'YYYY-MM-DD')));
  if v_kind_filter is not null then v_kind_filters := regexp_split_to_array(v_kind_filter, '\s*,\s*'); else v_kind_filters := null; end if;

  select active_provider, active_model, active_dimensions, active_task into v_provider, v_model, v_dims, v_task from public.embedding_settings where id = 1;
  select coalesce((select array_agg(x) from jsonb_array_elements_text(up.recsys->'mutedGenres') x), '{}'::text[]) into v_muted_genres from public.user_preferences up where up.user_id = v_user_id;

  select exists(select 1 from public.media_events e where e.user_id = v_user_id and e.created_at > now() - interval '120 days' and (e.event_type::text='like' or (e.event_type::text='watchlist' and e.in_watchlist=true) or (e.event_type::text='rating' and e.rating_0_10>=7) or (e.event_type::text='dwell' and e.dwell_ms>=6000) or (e.event_type::text='detail_open'))) into v_has_any_events;

  select sv.taste, sv.updated_at into v_session_vec, v_session_updated from public.media_session_vectors sv where sv.user_id=v_user_id and sv.session_id=p_session_id and sv.provider=v_provider and sv.model=v_model and sv.dimensions=v_dims and sv.task=v_task order by sv.updated_at desc limit 1;
  if v_session_updated is not null then v_session_age_seconds := extract(epoch from (now() - v_session_updated)); v_session_weight := exp(-v_session_age_seconds / (45*60.0)); end if;

  select uv.taste into v_user_vec from public.media_user_vectors uv where uv.user_id=v_user_id and uv.provider=v_provider and uv.model=v_model and uv.dimensions=v_dims and uv.task=v_task order by uv.updated_at desc limit 1;
  v_has_vec := (v_user_vec is not null) or (v_session_vec is not null) or exists(select 1 from public.media_user_centroids c where c.user_id=v_user_id and c.provider=v_provider and c.model=v_model and c.dimensions=v_dims and c.task=v_task);

  select e.media_item_id into v_recent_like_id from public.media_events e where e.user_id=v_user_id and e.created_at > now() - interval '30 days' and (e.event_type::text='like' or (e.event_type::text='watchlist' and e.in_watchlist=true) or (e.event_type::text='rating' and e.rating_0_10>=7) or (e.event_type::text='dwell' and e.dwell_ms>=6000) or (e.event_type::text='detail_open')) order by e.created_at desc limit 1;
  if v_recent_like_id is not null then select coalesce(mi.tmdb_title, mi.tmdb_name, mi.omdb_title) into v_recent_like_title from public.media_items mi where mi.id=v_recent_like_id; end if;

  create temporary table if not exists _cand (media_item_id uuid primary key, source text not null, score double precision not null, jit double precision not null, final_score double precision not null, primary_genre text, collection_id text, friend_ids uuid[], anchor_media_id uuid, anchor_title text) on commit drop;
  truncate table _cand;
  create temporary table if not exists _take (media_item_id uuid primary key, source text not null, final_score double precision not null, primary_genre text, collection_id text, friend_ids uuid[], anchor_title text) on commit drop;
  truncate table _take;
  create temporary table if not exists _picked (pos int primary key, media_item_id uuid not null, source text not null, final_score double precision not null, friend_ids uuid[], anchor_title text) on commit drop;
  truncate table _picked;
  create temporary table if not exists _seen24h (media_item_id uuid primary key) on commit drop;
  truncate table _seen24h;

  insert into _seen24h(media_item_id) select x.media_item_id from (select mf.media_item_id from public.media_feedback mf where mf.user_id = v_user_id and mf.last_impression_at is not null and mf.last_impression_at > now() - interval '24 hours' union select e.media_item_id from public.media_events e where e.user_id = v_user_id and e.created_at > now() - interval '24 hours' and e.event_type::text in ('impression','dwell','skip','detail_open','detail_close', 'like', 'dislike')) x on conflict (media_item_id) do nothing;

  create temporary table if not exists _blocked (media_item_id uuid primary key) on commit drop;
  truncate table _blocked;
  insert into _blocked(media_item_id) select x.media_item_id from (select mf.media_item_id from public.media_feedback mf where mf.user_id = v_user_id and (mf.last_action::text = 'dislike' or coalesce(mf.negative_ema,0) >= 0.95) union select e.media_item_id from public.media_events e where e.user_id = v_user_id and e.created_at > now() - interval '365 days' and (e.event_type = 'dislike'::public.media_event_type or (e.event_type::text='rating' and e.rating_0_10 is not null and e.rating_0_10 <= 3))) x on conflict (media_item_id) do nothing;

  create temporary table if not exists _served30m (media_item_id uuid primary key) on commit drop;
  truncate table _served30m;

  -- ALIGNMENT FIX: Use rec_impressions instead of the dropped media_served table
  insert into _served30m(media_item_id)
  select ri.media_item_id
  from public.rec_impressions ri
  where ri.user_id = v_user_id
    and ri.created_at > now() - interval '30 minutes'
  on conflict (media_item_id) do nothing;

  -- (Rest of the function logic remains the same as 20260116223000 but it must be fully defined)
  with params as (select v_mode as mode, v_kind_filters as kind_filters, v_seed as seed, v_has_vec as has_vec),
  cents as (select taste from public.media_user_centroids c where c.user_id=v_user_id and c.provider=v_provider and c.model=v_model and c.dimensions=v_dims and c.task=v_task order by c.centroid asc limit 3),
  pos_anchors as (select e.media_item_id as anchor_id, me.embedding as anchor_emb, e.created_at from public.media_events e join public.media_embeddings me on me.media_item_id = e.media_item_id where e.user_id = v_user_id and e.created_at > now() - interval '120 days' and (e.event_type::text='like' or (e.event_type::text='watchlist' and e.in_watchlist=true) or (e.event_type::text='rating' and e.rating_0_10>=7) or (e.event_type::text='dwell' and e.dwell_ms>=6000) or (e.event_type::text='detail_open')) and me.provider=v_provider and me.model=v_model and me.dimensions=v_dims and me.task=v_task and not exists (select 1 from _blocked b where b.media_item_id = e.media_item_id) order by e.created_at desc limit 10),
  anchor_neighbors_raw as (select n.media_item_id, n.anchor_id, n.sim from pos_anchors a cross join lateral (select a.anchor_id, me2.media_item_id, (1 - (me2.embedding <=> a.anchor_emb))::double precision as sim from public.media_embeddings me2 where me2.provider=v_provider and me2.model=v_model and me2.dimensions=v_dims and me2.task=v_task and me2.media_item_id <> a.anchor_id and not exists (select 1 from _blocked b where b.media_item_id = me2.media_item_id) order by me2.embedding <=> a.anchor_emb limit (v_limit * 20)) n),
  anchor_neighbors as (select r.media_item_id, max(r.sim) as score, (array_agg(r.anchor_id order by r.sim desc))[1] as best_anchor_id from anchor_neighbors_raw r group by r.media_item_id order by score desc limit (v_limit * 60)),
  anchor_neighbors_labeled as (select an.media_item_id, an.score, an.best_anchor_id as anchor_media_id, coalesce(mi.tmdb_title, mi.tmdb_name, mi.omdb_title) as anchor_title from anchor_neighbors an left join public.media_items mi on mi.id = an.best_anchor_id),
  session_neighbors as (select e.media_item_id, ((1 - (e.embedding <=> v_session_vec)) * v_session_weight)::double precision as score from public.media_embeddings e, params p where p.has_vec and v_session_vec is not null and e.provider=v_provider and e.model=v_model and e.dimensions=v_dims and e.task=v_task and not exists (select 1 from _blocked b where b.media_item_id=e.media_item_id) order by e.embedding <=> v_session_vec limit (v_limit * 30)),
  user_neighbors as (select e.media_item_id, (1 - (e.embedding <=> v_user_vec))::double precision as score from public.media_embeddings e, params p where p.has_vec and v_user_vec is not null and e.provider=v_provider and e.model=v_model and e.dimensions=v_dims and e.task=v_task and not exists (select 1 from _blocked b where b.media_item_id=e.media_item_id) order by e.embedding <=> v_user_vec limit (v_limit * 30)),
  centroid_neighbors_raw as (select n.media_item_id, n.sim from cents c cross join lateral (select me2.media_item_id, (1 - (me2.embedding <=> c.taste))::double precision as sim from public.media_embeddings me2, params p where p.has_vec and me2.provider=v_provider and me2.model=v_model and me2.dimensions=v_dims and me2.task=v_task and not exists (select 1 from _blocked b where b.media_item_id = me2.media_item_id) order by me2.embedding <=> c.taste limit (v_limit * 20)) n),
  centroid_neighbors as (select r.media_item_id, max(r.sim) as score from centroid_neighbors_raw r group by r.media_item_id order by score desc limit (v_limit * 40)),
  for_you_centroid_candidates as (select * from session_neighbors union all select * from user_neighbors union all select * from centroid_neighbors),
  for_you_centroid as (select c.media_item_id, max(c.score)::double precision as score from for_you_centroid_candidates c group by c.media_item_id order by score desc limit (v_limit * 30)),
  for_you_learning as (select mi.id as media_item_id, (coalesce(mi.tmdb_popularity,0)::double precision * 0.65 + coalesce(mi.tmdb_vote_average,0)::double precision * 8.0 + 0.15 * ((((hashtext(v_seed || mi.id::text))::bigint % 100000 + 100000) % 100000)::double precision / 100000.0)) as score from public.media_items mi where (not v_has_any_events) and (not v_has_vec) and coalesce(mi.completeness,1.0) >= 0.25 and (v_kind_filters is null or lower(mi.kind::text) = any (v_kind_filters)) and mi.id not in (select media_item_id from _blocked) order by score desc limit (v_limit * 50)),
  trending_recent as (select t.media_item_id, (t.score_72h * exp(-extract(epoch from (now() - t.computed_at)) / (18*3600.0)))::double precision as score from public.media_trending_scores t join public.media_items mi on mi.id=t.media_item_id where not exists (select 1 from _blocked b where b.media_item_id=t.media_item_id) and coalesce(mi.tmdb_release_date, mi.tmdb_first_air_date) >= ((now()::date - interval '6 months')::date) order by score desc limit (v_limit * 30)),
  popular_catalog as (select t.media_item_id, (t.score_72h * exp(-extract(epoch from (now() - t.computed_at)) / (24*3600.0)) * 0.55)::double precision as score from public.media_trending_scores t join public.media_items mi on mi.id=t.media_item_id where not exists (select 1 from _blocked b where b.media_item_id=t.media_item_id) and coalesce(mi.tmdb_release_date, mi.tmdb_first_air_date) < ((now()::date - interval '6 months')::date) order by score desc limit (v_limit * 10)),
  friend_events as (select e.media_item_id, e.user_id as friend_id, e.created_at, case when e.event_type::text='like' then 2.0 when e.event_type::text='watchlist' and e.in_watchlist=true then 1.6 when e.event_type::text='rating' and e.rating_0_10>=7 then 1.2 when e.event_type::text='dwell' and e.dwell_ms>=6000 then 0.8 else 0.0 end as w from public.follows f join public.media_events e on e.user_id=f.followed_id where f.follower_id=v_user_id and e.created_at > now() - interval '45 days' and e.event_type::text in ('like','watchlist','rating','dwell')),
  friends as (select fe.media_item_id, sum(fe.w * exp(-extract(epoch from (now()-fe.created_at))/(7*24*3600.0)))::double precision as score, array_agg(distinct fe.friend_id) as friend_ids from friend_events fe where fe.w > 0 and not exists (select 1 from _blocked b where b.media_item_id=fe.media_item_id) group by fe.media_item_id order by score desc limit (v_limit * 30)),
  for_you_pool as (select anl.media_item_id, anl.score, 'for_you'::text as source, null::uuid[] as friend_ids, anl.anchor_media_id, anl.anchor_title from anchor_neighbors_labeled anl union all select fyc.media_item_id, (fyc.score * 0.95) as score, 'for_you'::text as source, null::uuid[] as friend_ids, null::uuid as anchor_media_id, null::text as anchor_title from for_you_centroid fyc union all select fl.media_item_id, (fl.score * 0.8) as score, 'for_you'::text as source, null::uuid[] as friend_ids, null::uuid as anchor_media_id, null::text as anchor_title from for_you_learning fl)
  insert into _cand(media_item_id, source, score, jit, final_score, friend_ids, anchor_media_id, anchor_title)
  select distinct on (x.media_item_id)
    x.media_item_id,
    x.source,
    x.score,
    0.0 as jit,
    x.score as final_score,
    x.friend_ids,
    x.anchor_media_id,
    x.anchor_title
  from (
    select * from for_you_pool where v_mode in ('for_you', 'combined')
    union all
    select media_item_id, score, 'trending'::text, null::uuid[], null::uuid, null::text
    from trending_recent
    where v_mode in ('trending', 'combined')
    union all
    select media_item_id, score, 'trending'::text, null::uuid[], null::uuid, null::text
    from popular_catalog
    where v_mode in ('trending', 'combined')
    union all
    select media_item_id, score, 'friends'::text, friend_ids, null::uuid, null::text
    from friends
    where v_mode in ('friends', 'combined')
  ) x
  where not exists (select 1 from _blocked b where b.media_item_id=x.media_item_id) and not exists (select 1 from _served30m s where s.media_item_id=x.media_item_id)
  order by x.media_item_id, x.score desc
  on conflict (media_item_id) do update set score = greatest(_cand.score, excluded.score), source = case when excluded.score > _cand.score then excluded.source else _cand.source end, friend_ids = case when excluded.friend_ids is not null then excluded.friend_ids else _cand.friend_ids end;

  update _cand
  set jit = ((((hashtext(v_seed || media_item_id::text))::bigint % 100000 + 100000) % 100000)::double precision / 100000.0)
  where true;
  update _cand
  set final_score = case when source='for_you' then score + (jit * 0.05) when source='friends' then score + (jit * 0.05) else score + (jit * 0.15) end
  where true;
  if v_kind_filters is not null then delete from _cand c using public.media_items mi where c.media_item_id = mi.id and not (lower(mi.kind::text) = any(v_kind_filters)); else delete from _cand c using public.media_items mi where c.media_item_id = mi.id and lower(mi.kind::text) in ('episode', 'other'); end if;
  if array_length(v_muted_genres, 1) > 0 then delete from _cand c using public.media_items mi where c.media_item_id = mi.id and exists (select 1 from unnest(regexp_split_to_array(lower(coalesce(mi.omdb_genre,'')), '\s*,\s*')) t where t = any(v_muted_genres)); end if;
  update _cand set primary_genre = (regexp_split_to_array(mi.omdb_genre, ','))[1], collection_id = (mi.tmdb_belongs_to_collection ->> 'id') from public.media_items mi where _cand.media_item_id = mi.id;
  insert into _take select * from _cand order by final_score desc limit (v_limit * 3);

  declare
    _r record; _taken_ids uuid[] := '{}'; _genre_counts jsonb := '{}'::jsonb; _coll_counts jsonb := '{}'::jsonb; _g text; _c text; _ok boolean;
  begin
    for _r in (select * from _take order by final_score desc) loop
      if coalesce(array_length(_taken_ids,1), 0) >= v_limit then exit; end if;
      _ok := true; _g := lower(coalesce(_r.primary_genre, 'unknown')); _c := _r.collection_id;
      if (_genre_counts->>_g)::int >= v_genre_cap then _ok := false; end if;
      if _c is not null and (_coll_counts->>_c)::int >= v_collection_cap then _ok := false; end if;
      if _ok then
        insert into _picked(pos, media_item_id, source, final_score, friend_ids, anchor_title) values (coalesce(array_length(_taken_ids,1), 0)+1, _r.media_item_id, _r.source, _r.final_score, _r.friend_ids, _r.anchor_title);
        _taken_ids := _taken_ids || _r.media_item_id;
        _genre_counts := jsonb_set(_genre_counts, array[_g], ((coalesce(_genre_counts->>_g, '0')::int + 1)::text)::jsonb);
        if _c is not null then _coll_counts := jsonb_set(_coll_counts, array[_c], ((coalesce(_coll_counts->>_c, '0')::int + 1)::text)::jsonb); end if;
      end if;
    end loop;
    if coalesce(array_length(_taken_ids,1), 0) < v_limit then
      for _r in (select * from _take where not (media_item_id = any(_taken_ids)) order by final_score desc) loop
        if coalesce(array_length(_taken_ids,1), 0) >= v_limit then exit; end if;
        insert into _picked(pos, media_item_id, source, final_score, friend_ids, anchor_title) values (coalesce(array_length(_taken_ids,1), 0)+1, _r.media_item_id, _r.source, _r.final_score, _r.friend_ids, _r.anchor_title);
        _taken_ids := _taken_ids || _r.media_item_id;
      end loop;
    end if;
  end;

  return query select mi.id as media_item_id, coalesce(mi.tmdb_title, mi.tmdb_name, mi.omdb_title) as title, coalesce(mi.tmdb_overview, mi.omdb_plot) as overview, mi.kind::text as kind, mi.tmdb_release_date as release_date, mi.tmdb_first_air_date as first_air_date, mi.omdb_runtime, mi.tmdb_poster_path as poster_path, mi.tmdb_backdrop_path as backdrop_path, mi.tmdb_vote_average as vote_average, mi.tmdb_vote_count as vote_count, mi.tmdb_popularity as popularity, mi.completeness, p.source, case when p.source='friends' then 'Recommended by friends' when p.source='trending' then 'Trending on MoviNesta' when p.source='for_you' and p.anchor_title is not null then 'Because you liked ' || p.anchor_title else 'Recommended for you' end as why, p.friend_ids from _picked p join public.media_items mi on mi.id = p.media_item_id order by p.pos asc;
end;
$function$;

-----------------------------------------------------------------------
-- 2. Fix assistant_ctx_snapshot_v1 (Use assistant_goals columns)
-----------------------------------------------------------------------
CREATE OR REPLACE FUNCTION public.assistant_ctx_snapshot_v1(p_limit integer DEFAULT 20)
 RETURNS jsonb
 LANGUAGE plpgsql
 SECURITY DEFINER
 SET search_path TO 'public'
AS $function$
declare
  v_uid uuid := auth.uid();
  v_profile jsonb;
  v_prefs jsonb;
  v_library_total int;
  v_library_by_status jsonb;
  v_lists_count int;
  v_likes_count int;
  v_lists jsonb;
  v_recent_library jsonb;
  v_recent_likes jsonb;
  v_goals jsonb;
  v_limit int := greatest(1, least(100, coalesce(p_limit, 20)));
begin
  if v_uid is null then return null; end if;

  select to_jsonb(p) into v_profile from public.profiles_public p where p.id = v_uid;
  select to_jsonb(up) into v_prefs from public.user_preferences up where up.user_id = v_uid;

  select count(*)::int into v_library_total from public.media_library where user_id = v_uid;
  select coalesce(jsonb_object_agg(status, cnt), '{}'::jsonb) into v_library_by_status from (select status, count(*)::int as cnt from public.media_library where user_id = v_uid group by status) s;
  select count(*)::int into v_lists_count from public.lists where user_id = v_uid;
  select count(*)::int into v_likes_count from public.media_events where user_id = v_uid and event_type = 'like';

  select coalesce(jsonb_agg(to_jsonb(l) - 'user_id'), '[]'::jsonb) into v_lists from (select * from public.lists where user_id = v_uid order by updated_at desc limit 10) l;

  select coalesce(jsonb_agg(jsonb_build_object('id', mi.id, 'title', coalesce(mi.tmdb_title, mi.omdb_title), 'status', ml.status, 'addedAt', ml.created_at)), '[]'::jsonb)
  into v_recent_library
  from (select media_item_id, status, created_at from public.media_library where user_id = v_uid order by created_at desc limit v_limit) ml
  join public.media_items mi on mi.id = ml.media_item_id;

  select coalesce(jsonb_agg(jsonb_build_object('id', mi.id, 'title', coalesce(mi.tmdb_title, mi.omdb_title), 'likedAt', e.created_at)), '[]'::jsonb)
  into v_recent_likes
  from (select media_item_id, created_at from public.media_events where user_id = v_uid and event_type = 'like' order by created_at desc limit v_limit) e
  join public.media_items mi on mi.id = e.media_item_id;

  -- ALIGNMENT FIX: Read from assistant_goals columns instead of assistant_goal_state
  select coalesce(
    jsonb_agg(
      jsonb_build_object(
        'id', g.id,
        'kind', g.kind,
        'title', g.title,
        'description', g.description,
        'status', g.status,
        'startAt', g.start_at,
        'endAt', g.end_at,
        'progressCount', g.progress_count,
        'targetCount', g.target_count,
        'lastEventAt', g.updated_at
      )
      order by g.updated_at desc
    ),
    '[]'::jsonb
  )
  into v_goals
  from public.assistant_goals g
  where g.user_id = v_uid and g.status = 'active'
  order by g.updated_at desc
  limit 5;

  return jsonb_build_object(
    'ok', true,
    'profile', coalesce(v_profile, '{}'::jsonb),
    'prefs', coalesce(v_prefs, '{}'::jsonb),
    'stats', jsonb_build_object(
      'libraryTotal', coalesce(v_library_total, 0),
      'libraryByStatus', coalesce(v_library_by_status, '{}'::jsonb),
      'listsCount', coalesce(v_lists_count, 0),
      'likesCount', coalesce(v_likes_count, 0)
    ),
    'lists', coalesce(v_lists, '[]'::jsonb),
    'recentLibrary', coalesce(v_recent_library, '[]'::jsonb),
    'recentLikes', coalesce(v_recent_likes, '[]'::jsonb),
    'activeGoals', coalesce(v_goals, '[]'::jsonb)
  );
end;
$function$;

-----------------------------------------------------------------------
-- 3. Fix assistant_goal_refresh_state (Use assistant_goals columns)
-----------------------------------------------------------------------
CREATE OR REPLACE FUNCTION public.assistant_goal_refresh_state(p_goal_id uuid)
 RETURNS void
 LANGUAGE plpgsql
 SECURITY DEFINER
 SET search_path TO 'public'
AS $function$
declare
  tcount int;
  pcount int;
begin
  select coalesce((g.meta->>'targetCount')::int, (g.meta->>'target_count')::int, 0)
    into tcount
  from public.assistant_goals g
  where g.id = p_goal_id;

  select count(*)::int
    into pcount
  from public.assistant_goal_events e
  where e.goal_id = p_goal_id
    and e.event_type = 'watched';

  -- ALIGNMENT FIX: Update assistant_goals directly
  UPDATE public.assistant_goals
  SET 
    target_count = coalesce(tcount, 0),
    progress_count = coalesce(pcount, 0),
    updated_at = now()
  WHERE id = p_goal_id;
end;
$function$;

-----------------------------------------------------------------------
-- 4. Fix assistant_health_snapshot_v1 (Use ops_alerts for failures)
-----------------------------------------------------------------------
CREATE OR REPLACE FUNCTION public.assistant_health_snapshot_v1()
 RETURNS jsonb
 LANGUAGE plpgsql
 SECURITY DEFINER
 SET search_path TO 'public'
AS $function$
DECLARE
  v_now timestamptz := now();
  v_counts jsonb;
  v_by_kind jsonb;
  v_oldest_pending bigint;
  v_oldest_processing bigint;
  v_last24 jsonb;
  v_failures jsonb;
  v_ai_failures jsonb;
  v_cron jsonb;
BEGIN
  PERFORM public.assert_admin();

  SELECT COALESCE(jsonb_object_agg(status, cnt), '{}'::jsonb) INTO v_counts
  FROM (SELECT status, count(*)::int AS cnt FROM public.assistant_reply_jobs GROUP BY status) s;

  WITH k AS (
    SELECT job_kind, sum((status = 'pending')::int) AS pending, sum((status = 'processing')::int) AS processing, sum((status = 'done')::int) AS done, sum((status = 'failed')::int) AS failed, count(*)::int AS total
    FROM public.assistant_reply_jobs GROUP BY job_kind
  )
  SELECT COALESCE(jsonb_object_agg(job_kind, jsonb_build_object('pending', pending, 'processing', processing, 'done', done, 'failed', failed, 'total', total)), '{}'::jsonb)
  INTO v_by_kind FROM k;

  SELECT floor(extract(epoch from (v_now - min(created_at))))::bigint INTO v_oldest_pending FROM public.assistant_reply_jobs WHERE status = 'pending';
  SELECT floor(extract(epoch from (v_now - min(updated_at))))::bigint INTO v_oldest_processing FROM public.assistant_reply_jobs WHERE status = 'processing';

  SELECT jsonb_build_object('created', count(*)::int, 'done', sum((status = 'done')::int), 'failed', sum((status = 'failed')::int))
  INTO v_last24 FROM public.assistant_reply_jobs WHERE created_at >= (v_now - interval '24 hours');

  SELECT COALESCE(jsonb_agg(jsonb_build_object('id', id, 'conversationId', conversation_id, 'userId', user_id, 'jobKind', job_kind, 'attempts', attempts, 'updatedAt', updated_at, 'lastError', left(coalesce(last_error, ''), 220)) ORDER BY updated_at DESC), '[]'::jsonb)
  INTO v_failures FROM (SELECT * FROM public.assistant_reply_jobs WHERE status = 'failed' ORDER BY updated_at DESC LIMIT 20) f;

  -- ALIGNMENT FIX: Use ops_alerts instead of dropped assistant_failures table
  SELECT COALESCE(jsonb_agg(
    jsonb_build_object(
      'id', id,
      'createdAt', created_at,
      'requestId', request_id,
      'userId', user_id,
      'code', code,
      'reason', message,
      'context', left(context::text, 500)
    )
    ORDER BY created_at DESC
  ), '[]'::jsonb)
  INTO v_ai_failures
  FROM (
    SELECT *
    FROM public.ops_alerts
    WHERE kind = 'assistant_failure'
      AND created_at >= (v_now - interval '72 hours')
    ORDER BY created_at DESC
    LIMIT 50
  ) af;

  SELECT COALESCE(jsonb_agg(jsonb_build_object('id', id, 'job', job_name, 'requestId', request_id, 'createdAt', created_at) ORDER BY created_at DESC), '[]'::jsonb)
  INTO v_cron FROM (SELECT id, job_name, request_id, created_at FROM public.assistant_cron_requests ORDER BY created_at DESC LIMIT 25) c;

  RETURN jsonb_build_object(
    'ok', true,
    'ts', v_now,
    'counts', v_counts,
    'byKind', v_by_kind,
    'oldestPendingSec', COALESCE(v_oldest_pending, 0),
    'oldestProcessingSec', COALESCE(v_oldest_processing, 0),
    'last24h', COALESCE(v_last24, '{}'::jsonb),
    'recentFailures', v_failures,
    'recentAiFailures', COALESCE(v_ai_failures, '[]'::jsonb),
    'recentCron', v_cron
  );
END;
$function$;

-----------------------------------------------------------------------
-- 5. Fix RecSys Analysis Views (Use media_events instead of rec_outcomes)
-----------------------------------------------------------------------

-- rec_position_daily_metrics_v1
CREATE OR REPLACE VIEW public.rec_position_daily_metrics_v1 WITH (security_invoker='true') AS
 WITH imp AS (
         SELECT (date_trunc('day'::text, i.created_at))::date AS day,
            i.user_id,
            i.rec_request_id,
            i.media_item_id,
            i."position"
           FROM public.rec_impressions i
        ), outc AS (
         SELECT o_1.user_id,
            o_1.rec_request_id,
            o_1.media_item_id,
            o_1.event_type as outcome_type,
            o_1.created_at
           FROM public.media_events o_1
           WHERE o_1.rec_request_id IS NOT NULL
        )
 SELECT imp.day,
    imp."position",
    count(*) AS impressions,
    count(*) FILTER (WHERE (o.outcome_type::text = ANY (ARRAY['like'::text]))) AS likes,
    count(*) FILTER (WHERE (o.outcome_type::text = ANY (ARRAY['dislike'::text]))) AS dislikes,
    count(*) FILTER (WHERE (o.outcome_type::text IN ('watchlist_add'::text, 'watchlist'::text))) AS watchlist_adds,
    count(*) FILTER (WHERE (o.outcome_type::text IN ('detail_open'::text))) AS detail_opens,
    ((count(*) FILTER (WHERE (o.outcome_type::text = ANY (ARRAY['like'::text]))))::numeric / NULLIF((count(*))::numeric, (0)::numeric)) AS like_rate,
    ((count(*) FILTER (WHERE (o.outcome_type::text = ANY (ARRAY['dislike'::text]))))::numeric / NULLIF((count(*))::numeric, (0)::numeric)) AS dislike_rate
   FROM (imp
     LEFT JOIN LATERAL ( SELECT o_1.outcome_type
           FROM outc o_1
          WHERE ((o_1.user_id = imp.user_id) AND (o_1.rec_request_id = imp.rec_request_id) AND (o_1.media_item_id = imp.media_item_id) AND (o_1.created_at >= (imp.day)::timestamp with time zone) AND (o_1.created_at < ((imp.day)::timestamp with time zone + '1 day'::interval)))
          ORDER BY o_1.created_at
         LIMIT 1) o ON (true))
  GROUP BY imp.day, imp."position"
  ORDER BY imp.day DESC, imp."position";

-- rec_variant_daily_metrics_v1
CREATE OR REPLACE VIEW public.rec_variant_daily_metrics_v1 WITH (security_invoker='true') AS
 WITH impressions AS (
         SELECT (date_trunc('day'::text, i.created_at))::date AS day,
            i.id AS impression_id,
            i.user_id,
            i.rec_request_id,
            i.media_item_id,
            COALESCE((i.request_context -> 'experiments'::text), '{}'::jsonb) AS experiments
           FROM public.rec_impressions i
        ), expanded AS (
         SELECT impressions.day,
            impressions.impression_id,
            impressions.user_id,
            impressions.rec_request_id,
            impressions.media_item_id,
            e_1.key AS experiment_key,
            e_1.value AS variant
           FROM (impressions
             CROSS JOIN LATERAL jsonb_each_text(impressions.experiments) e_1(key, value))
        ), outcomes_agg AS (
         SELECT o_1.user_id,
            o_1.rec_request_id,
            o_1.media_item_id,
            bool_or((o_1.event_type::text IN ('detail_open'::text))) AS opened_detail,
            bool_or((o_1.event_type::text IN ('like'::text))) AS liked,
            bool_or((o_1.event_type::text IN ('dislike'::text))) AS disliked,
            bool_or((o_1.event_type::text IN ('watchlist_add'::text, 'watchlist'::text))) AS watchlist_add,
            bool_or((o_1.event_type::text IN ('rating'::text, 'rating_set'::text))) AS rated
           FROM public.media_events o_1
           WHERE o_1.rec_request_id IS NOT NULL
          GROUP BY o_1.user_id, o_1.rec_request_id, o_1.media_item_id
        )
 SELECT e.day,
    e.experiment_key,
    e.variant,
    count(*) AS impressions,
    count(DISTINCT e.user_id) AS users,
    count(*) FILTER (WHERE o.opened_detail) AS detail_opens,
    count(*) FILTER (WHERE o.liked) AS likes,
    count(*) FILTER (WHERE o.disliked) AS dislikes,
    count(*) FILTER (WHERE o.watchlist_add) AS watchlist_adds,
    count(*) FILTER (WHERE o.rated) AS ratings,
    ((count(*) FILTER (WHERE o.liked))::double precision / (NULLIF(count(*), 0))::double precision) AS like_rate,
    ((count(*) FILTER (WHERE o.watchlist_add))::double precision / (NULLIF(count(*), 0))::double precision) AS watchlist_add_rate
   FROM (expanded e
     LEFT JOIN outcomes_agg o ON (((o.user_id = e.user_id) AND (o.rec_request_id = e.rec_request_id) AND (o.media_item_id = e.media_item_id))))
  GROUP BY e.day, e.experiment_key, e.variant;

COMMIT;



-- -----------------------------------------------------------------------------
-- File: 20260116235900_security_audit_fixes.sql
-- -----------------------------------------------------------------------------
-- Migration: 20260116235900_security_audit_fixes.sql
-- Description: Enable Row Level Security (RLS) and define access policies for tables flagged by security linter.

BEGIN;

-----------------------------------------------------------------------
-- 1. System and Cache Tables
-- These tables should only be accessible by the service_role (internal).
-- Enabling RLS without adding any public/authenticated policies effectively
-- locks them down to the service_role, which bypasses RLS.
-----------------------------------------------------------------------
ALTER TABLE public.external_api_cache ENABLE ROW LEVEL SECURITY;
ALTER TABLE public.media_metadata_cache ENABLE ROW LEVEL SECURITY;
ALTER TABLE public.rate_limits ENABLE ROW LEVEL SECURITY;

-----------------------------------------------------------------------
-- 2. Media Embeddings
-- Authenticated users need to read embeddings for similarity searches.
-----------------------------------------------------------------------
ALTER TABLE public.media_embeddings ENABLE ROW LEVEL SECURITY;

DROP POLICY IF EXISTS "Embeddings are viewable by authenticated users" ON public.media_embeddings;
CREATE POLICY "Embeddings are viewable by authenticated users" 
    ON public.media_embeddings FOR SELECT 
    USING (auth.role() = 'authenticated');

-----------------------------------------------------------------------
-- 3. Media Events (Partitioned Table)
-- Users should only be able to see and insert their own events.
-----------------------------------------------------------------------
ALTER TABLE public.media_events ENABLE ROW LEVEL SECURITY;

DROP POLICY IF EXISTS "Users can insert their own events" ON public.media_events;
CREATE POLICY "Users can insert their own events" 
    ON public.media_events FOR INSERT 
    WITH CHECK (auth.uid() = user_id);

DROP POLICY IF EXISTS "Users can view their own events" ON public.media_events;
CREATE POLICY "Users can view their own events" 
    ON public.media_events FOR SELECT 
    USING (auth.uid() = user_id);

-----------------------------------------------------------------------
-- 4. Recommendation Impressions (Partitioned Table)
-- Users should only be able to see and insert their own impressions.
-----------------------------------------------------------------------
ALTER TABLE public.rec_impressions ENABLE ROW LEVEL SECURITY;

DROP POLICY IF EXISTS "Users can insert their own impressions" ON public.rec_impressions;
CREATE POLICY "Users can insert their own impressions" 
    ON public.rec_impressions FOR INSERT 
    WITH CHECK (auth.uid() = user_id);

DROP POLICY IF EXISTS "Users can view their own impressions" ON public.rec_impressions;
CREATE POLICY "Users can view their own impressions" 
    ON public.rec_impressions FOR SELECT 
    USING (auth.uid() = user_id);

-----------------------------------------------------------------------
-- 5. Enable RLS on all existing partitions
-- Partitions in PostgreSQL must also have RLS enabled.
-----------------------------------------------------------------------
DO $$
DECLARE
    partition_name text;
BEGIN
    FOR partition_name IN 
        SELECT tablename 
        FROM pg_tables 
        WHERE schemaname = 'public' 
        AND (tablename LIKE 'media_events_%' OR tablename LIKE 'rec_impressions_%')
    LOOP
        EXECUTE format('ALTER TABLE public.%I ENABLE ROW LEVEL SECURITY', partition_name);
    END LOOP;
END $$;

COMMIT;



-- -----------------------------------------------------------------------------
-- File: 20260116235910_security_audit_v2.sql
-- -----------------------------------------------------------------------------
-- Migration: 20260116235910_security_audit_v2.sql
-- Description: Fix mutable search paths for functions and restrict public access to materialized views.

BEGIN;

-----------------------------------------------------------------------
-- 1. Fix Mutable Search Paths for Maintenance Functions
-- Setting an explicit search_path prevents search path hijacking.
-----------------------------------------------------------------------

-- Functions from scheduled_maintenance.sql
ALTER FUNCTION public.run_scheduled_maintenance() SET search_path = public, extensions, pg_temp;
ALTER FUNCTION public.refresh_trending_hourly() SET search_path = public, extensions, pg_temp;

-- Functions from retention_policies.sql
ALTER FUNCTION public.cleanup_old_media_events_partitions() SET search_path = public, extensions, pg_temp;
ALTER FUNCTION public.cleanup_old_rec_impressions_partitions() SET search_path = public, extensions, pg_temp;
ALTER FUNCTION public.cleanup_old_notifications() SET search_path = public, extensions, pg_temp;
ALTER FUNCTION public.cleanup_stale_session_vectors() SET search_path = public, extensions, pg_temp;
ALTER FUNCTION public.run_data_retention_cleanup() SET search_path = public, extensions, pg_temp;

-- Functions from partition migrations
ALTER FUNCTION public.create_media_events_partition_if_needed() SET search_path = public, extensions, pg_temp;

-- Functions from materialized_views.sql
ALTER FUNCTION public.refresh_user_stats_mv() SET search_path = public, extensions, pg_temp;
ALTER FUNCTION public.refresh_media_trending_mv() SET search_path = public, extensions, pg_temp;

-----------------------------------------------------------------------
-- 2. Restrict Direct Access to Materialized Views
-- These views are meant for internal metrics or pre-computation.
-- To expose them securely, wrap them in SECURITY DEFINER RPCs.
-----------------------------------------------------------------------

REVOKE ALL ON public.user_stats_mv FROM public;
REVOKE ALL ON public.user_stats_mv FROM anon;
REVOKE ALL ON public.user_stats_mv FROM authenticated;
GRANT SELECT ON public.user_stats_mv TO service_role;

REVOKE ALL ON public.media_trending_mv FROM public;
REVOKE ALL ON public.media_trending_mv FROM anon;
REVOKE ALL ON public.media_trending_mv FROM authenticated;
GRANT SELECT ON public.media_trending_mv TO service_role;

COMMIT;



-- -----------------------------------------------------------------------------
-- File: 20260116235920_performance_audit_fixes.sql
-- -----------------------------------------------------------------------------
-- Migration: 20260116235920_performance_audit_fixes.sql
-- Description: Optimize RLS performance and prune duplicate indexes.

BEGIN;

-----------------------------------------------------------------------
-- 1. Optimize RLS Policies (auth_rls_initplan)
-- Wrapping auth.uid() and auth.role() in (SELECT ...) prevents
-- re-evaluation for every row, improving performance at scale.
-----------------------------------------------------------------------

-- user_preferences
DROP POLICY IF EXISTS "Users can view their own preferences" ON public.user_preferences;
CREATE POLICY "Users can view their own preferences" 
    ON public.user_preferences FOR SELECT 
    USING (auth.uid() = user_id);
-- Re-applying with performance fix
ALTER POLICY "Users can view their own preferences" ON public.user_preferences 
    USING (user_id = (SELECT auth.uid()));

DROP POLICY IF EXISTS "Users can update their own preferences" ON public.user_preferences;
CREATE POLICY "Users can update their own preferences" 
    ON public.user_preferences FOR UPDATE 
    USING (user_id = (SELECT auth.uid()));

DROP POLICY IF EXISTS "Users can insert their own preferences" ON public.user_preferences;
CREATE POLICY "Users can insert their own preferences" 
    ON public.user_preferences FOR INSERT 
    WITH CHECK (user_id = (SELECT auth.uid()));

-- media_embeddings
DROP POLICY IF EXISTS "Embeddings are viewable by authenticated users" ON public.media_embeddings;
CREATE POLICY "Embeddings are viewable by authenticated users" 
    ON public.media_embeddings FOR SELECT 
    USING ((SELECT auth.role()) = 'authenticated');

-- media_events (parent table policies apply to partitions)
DROP POLICY IF EXISTS "Users can insert their own events" ON public.media_events;
CREATE POLICY "Users can insert their own events" 
    ON public.media_events FOR INSERT 
    WITH CHECK (user_id = (SELECT auth.uid()));

DROP POLICY IF EXISTS "Users can view their own events" ON public.media_events;
CREATE POLICY "Users can view their own events" 
    ON public.media_events FOR SELECT 
    USING (user_id = (SELECT auth.uid()));

-- rec_impressions (parent table policies apply to partitions)
DROP POLICY IF EXISTS "Users can insert their own impressions" ON public.rec_impressions;
CREATE POLICY "Users can insert their own impressions" 
    ON public.rec_impressions FOR INSERT 
    WITH CHECK (user_id = (SELECT auth.uid()));

DROP POLICY IF EXISTS "Users can view their own impressions" ON public.rec_impressions;
CREATE POLICY "Users can view their own impressions" 
    ON public.rec_impressions FOR SELECT 
    USING (user_id = (SELECT auth.uid()));

-----------------------------------------------------------------------
-- 2. Internal Cache Security (rls_enabled_no_policy)
-- Adding explicit "deny all" for public/authenticated to silence linter
-- and document that only service_role (which bypasses RLS) can access these.
-----------------------------------------------------------------------
DROP POLICY IF EXISTS "Internal only" ON public.external_api_cache;
CREATE POLICY "Internal only" ON public.external_api_cache FOR ALL USING (false);

DROP POLICY IF EXISTS "Internal only" ON public.media_metadata_cache;
CREATE POLICY "Internal only" ON public.media_metadata_cache FOR ALL USING (false);

DROP POLICY IF EXISTS "Internal only" ON public.rate_limits;
CREATE POLICY "Internal only" ON public.rate_limits FOR ALL USING (false);

-----------------------------------------------------------------------
-- 3. Prune Duplicate Indexes
-- Removing redundant indexes identified by the linter.
-----------------------------------------------------------------------

-- media_trending_mv duplicate indexes
DROP INDEX IF EXISTS public.media_trending_mv_wilson_score_idx1;
DROP INDEX IF EXISTS public.media_trending_mv_wilson_score_idx2;
DROP INDEX IF EXISTS public.media_trending_mv_wilson_score_idx3;
DROP INDEX IF EXISTS public.media_trending_mv_wilson_score_idx4;
DROP INDEX IF EXISTS public.media_trending_mv_wilson_score_idx5;

DROP INDEX IF EXISTS public.media_trending_mv_media_item_id_idx1;
DROP INDEX IF EXISTS public.media_trending_mv_media_item_id_idx2;
DROP INDEX IF EXISTS public.media_trending_mv_media_item_id_idx3;
DROP INDEX IF EXISTS public.media_trending_mv_media_item_id_idx4;
DROP INDEX IF EXISTS public.media_trending_mv_media_item_id_idx5;

-- user_stats_mv duplicate indexes
DROP INDEX IF EXISTS public.user_stats_mv_user_id_idx1;
DROP INDEX IF EXISTS public.user_stats_mv_user_id_idx2;
DROP INDEX IF EXISTS public.user_stats_mv_user_id_idx3;
DROP INDEX IF EXISTS public.user_stats_mv_user_id_idx4;
DROP INDEX IF EXISTS public.user_stats_mv_user_id_idx5;

-- follows duplicate indexes
-- follows_followed_id_idx and idx_follows_followed are identical
DROP INDEX IF EXISTS public.follows_followed_id_idx;

-- messages duplicate indexes
-- idx_messages_conversation_time and messages_conversation_id_created_at_idx are identical
DROP INDEX IF EXISTS public.messages_conversation_id_created_at_idx;

-- notifications duplicate indexes
-- idx_notifications_user_unread and notifications_user_unread_created_at_idx are identical
DROP INDEX IF EXISTS public.notifications_user_unread_created_at_idx;

COMMIT;



-- -----------------------------------------------------------------------------
-- File: 20260116235930_final_audit_cleanup.sql
-- -----------------------------------------------------------------------------
-- Migration: 20260116235930_final_audit_cleanup.sql
-- Description: Prune leftover duplicate indexes from multiple regeneration attempts.

BEGIN;

-----------------------------------------------------------------------
-- 1. Prune Remaining Duplicate Indexes
-----------------------------------------------------------------------

-- media_trending_mv leftover duplicates
DROP INDEX IF EXISTS public.media_trending_mv_wilson_score_idx6;
DROP INDEX IF EXISTS public.media_trending_mv_media_item_id_idx6;

-- user_stats_mv leftover duplicate
DROP INDEX IF EXISTS public.user_stats_mv_user_id_idx6;

-----------------------------------------------------------------------
-- 2. Global RLS Synchronization for Partitions
-- Ensures every current partition explicitly has RLS enabled.
-- (Note: Policies are inherited from the parent and don't need to be 
--  duplicated, which is why the linter might show INFO/WARN about 
--  "no policies", but the inheritance is functionally active.)
-----------------------------------------------------------------------
DO $$
DECLARE
    partition_name text;
BEGIN
    FOR partition_name IN 
        SELECT tablename 
        FROM pg_tables 
        WHERE schemaname = 'public' 
        AND (tablename LIKE 'media_events_%' OR tablename LIKE 'rec_impressions_%')
    LOOP
        EXECUTE format('ALTER TABLE public.%I ENABLE ROW LEVEL SECURITY', partition_name);
    END LOOP;
END $$;

COMMIT;



-- -----------------------------------------------------------------------------
-- File: 20260116235940_silence_partition_rls_warnings.sql
-- -----------------------------------------------------------------------------
-- Migration: 20260116235940_silence_partition_rls_warnings.sql
-- Description: Explicitly apply RLS policies to partitions to satisfy Supabase security linter.

BEGIN;

-----------------------------------------------------------------------
-- 1. Explicitly apply policies to partitions
-- Even though PostgreSQL inherits parent policies, the Supabase audit
-- requires explicit declaration to clear "RLS Enabled No Policy" warnings.
-----------------------------------------------------------------------

DO $$
DECLARE
    partition_name text;
BEGIN
    -- Fix media_events partitions
    FOR partition_name IN 
        SELECT tablename 
        FROM pg_tables 
        WHERE schemaname = 'public' 
        AND (tablename LIKE 'media_events_%' OR tablename = 'media_events_default')
    LOOP
        EXECUTE format('DROP POLICY IF EXISTS "Partition users can insert" ON public.%I', partition_name);
        EXECUTE format('CREATE POLICY "Partition users can insert" ON public.%I FOR INSERT WITH CHECK (user_id = (SELECT auth.uid()))', partition_name);
        
        EXECUTE format('DROP POLICY IF EXISTS "Partition users can view" ON public.%I', partition_name);
        EXECUTE format('CREATE POLICY "Partition users can view" ON public.%I FOR SELECT USING (user_id = (SELECT auth.uid()))', partition_name);
    END LOOP;

    -- Fix rec_impressions partitions
    FOR partition_name IN 
        SELECT tablename 
        FROM pg_tables 
        WHERE schemaname = 'public' 
        AND (tablename LIKE 'rec_impressions_%' OR tablename = 'rec_impressions_default')
    LOOP
        EXECUTE format('DROP POLICY IF EXISTS "Partition users can insert" ON public.%I', partition_name);
        EXECUTE format('CREATE POLICY "Partition users can insert" ON public.%I FOR INSERT WITH CHECK (user_id = (SELECT auth.uid()))', partition_name);
        
        EXECUTE format('DROP POLICY IF EXISTS "Partition users can view" ON public.%I', partition_name);
        EXECUTE format('CREATE POLICY "Partition users can view" ON public.%I FOR SELECT USING (user_id = (SELECT auth.uid()))', partition_name);
    END LOOP;
END $$;

COMMIT;
